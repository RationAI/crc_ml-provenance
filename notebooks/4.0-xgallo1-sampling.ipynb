{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import timeit\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = []\n",
    "for i in range(10):\n",
    "    cancer.append('c{}'.format(i))\n",
    "    \n",
    "normal = []\n",
    "for i in range(1000):\n",
    "    normal.append('n{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(ratio_cancer):\n",
    "    prob_c = ratio_cancer / len(cancer)\n",
    "    prob_n = (1 - ratio_cancer) / len(normal)\n",
    "    probs = np.repeat([prob_c, prob_n], repeats=[len(cancer), len(normal)])\n",
    "    return np.random.choice(cancer + normal, size=100, replace=True, p=probs)\n",
    "\n",
    "def count(_sample):\n",
    "    return Counter([x[0] for x in _sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97d5583c1654>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "count(sample(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('/home/matejg/Project/crc_ml_model/data/processed/train_slides/')\n",
    "VALID_DIR = Path('/home/matejg/Project/crc_ml_model/data/processed/valid_slides/')\n",
    "VISUAL_DIR = Path('/home/matejg/Project/crc_ml_model/data/processed/visual_slides/')\n",
    "TEST_DIR = Path('/home/matejg/Project/crc_ml_model/data/processed/test_slides/')\n",
    "\n",
    "CANCER_SAMPLE_PROBA = 0.5\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6912 cancer tiles.\n",
      "Found 9554 normal tiles.\n"
     ]
    }
   ],
   "source": [
    "cancer_paths  = [str(path_) for path_ in TEST_DIR.glob('*/cancer/*.png')]\n",
    "normal_paths  = [str(path_) for path_ in TEST_DIR.glob('*/normal/*.png')]\n",
    "num_cancer = len(cancer_paths)\n",
    "num_normal = len(normal_paths)\n",
    "\n",
    "print('Found {} cancer tiles.'.format(num_cancer))\n",
    "print('Found {} normal tiles.'.format(num_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1748 cancer tiles.\n",
      "Found 21690 normal tiles.\n"
     ]
    }
   ],
   "source": [
    "def get_valid_dataset(batch_size, seed=None):\n",
    "    cancer_paths  = [str(path_) for path_ in VALID_DIR.glob('*/cancer/*.png')]\n",
    "    normal_paths  = [str(path_) for path_ in VALID_DIR.glob('*/normal/*.png')]\n",
    "    num_cancer = len(cancer_paths)\n",
    "    num_normal = len(normal_paths)\n",
    "    \n",
    "    print('Found {} cancer tiles.'.format(num_cancer))\n",
    "    print('Found {} normal tiles.'.format(num_normal))\n",
    "    \n",
    "    all_labels = np.array([1] * num_cancer + [0] * num_normal)\n",
    "    all_paths = np.array(cancer_paths + normal_paths)\n",
    "    del cancer_paths\n",
    "    del normal_paths\n",
    "    indices = np.arange(num_cancer + num_normal)\n",
    "    np.random.shuffle(indices)\n",
    "    all_labels = all_labels[indices]\n",
    "    all_paths = all_paths[indices]\n",
    "    del indices\n",
    "    \n",
    "    paths_ds = tf.data.Dataset.from_tensor_slices(all_paths).map(lambda x: _load_and_preprocess_image(x, seed=seed, apply_color_augmentation=False, apply_flip_augmentation=False))\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(all_labels)\n",
    "    res = tf.data.Dataset.zip((paths_ds, labels_ds))\n",
    "    del paths_ds, labels_ds\n",
    "    \n",
    "    res = res.batch(batch_size)\n",
    "    res = res.prefetch(buffer_size=AUTOTUNE)\n",
    "    return  all_paths, all_labels, res, int(np.ceil((num_cancer + num_normal) / batch_size))\n",
    "p, l, ds, steps = get_valid_dataset(32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019_1427-08-1', array(['/home/matejg/Project/crc_ml_model/data/processed/visual_slides/2019_1427-08-1/normal/2019_1427-08-1-tile-r402-c172-x51132-y119902-w299-h299.png',\n",
      "       '/home/matejg/Project/crc_ml_model/data/processed/visual_slides/2019_1427-08-1/cancer/2019_1427-08-1-tile-r412-c87-x25715-y122892-w299-h299.png',\n",
      "       '/home/matejg/Project/crc_ml_model/data/processed/visual_slides/2019_1427-08-1/normal/2019_1427-08-1-tile-r573-c174-x51730-y171033-w299-h299.png',\n",
      "       ...,\n",
      "       '/home/matejg/Project/crc_ml_model/data/processed/visual_slides/2019_1427-08-1/cancer/2019_1427-08-1-tile-r586-c150-x44554-y174920-w299-h299.png',\n",
      "       '/home/matejg/Project/crc_ml_model/data/processed/visual_slides/2019_1427-08-1/normal/2019_1427-08-1-tile-r403-c149-x44255-y120201-w299-h299.png',\n",
      "       '/home/matejg/Project/crc_ml_model/data/processed/visual_slides/2019_1427-08-1/cancer/2019_1427-08-1-tile-r582-c124-x36779-y173724-w299-h299.png'],\n",
      "      dtype='<U143'), array([0, 1, 0, ..., 1, 0, 1]), <DatasetV1Adapter shapes: ((?, 299, 299, 3), (?,)), types: (tf.float32, tf.int64)>, 195)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_test_dataset(batch_size, seed=None):\n",
    "    visual_sets = []\n",
    "    for visual_slide in VISUAL_DIR.iterdir():\n",
    "        cancer_paths  = [str(path_) for path_ in visual_slide.glob('cancer/*.png')]\n",
    "        normal_paths  = [str(path_) for path_ in visual_slide.glob('normal/*.png')]\n",
    "        num_cancer = len(cancer_paths)\n",
    "        num_normal = len(normal_paths)\n",
    "\n",
    "        all_labels = np.array([1] * num_cancer + [0] * num_normal)\n",
    "        all_paths = np.array(cancer_paths + normal_paths)\n",
    "        del cancer_paths\n",
    "        del normal_paths\n",
    "        indices = np.arange(num_cancer + num_normal)\n",
    "        np.random.shuffle(indices)\n",
    "        all_labels = all_labels[indices]\n",
    "        all_paths = all_paths[indices]\n",
    "        del indices\n",
    "\n",
    "        paths_ds = tf.data.Dataset.from_tensor_slices(all_paths).map(lambda x: _load_and_preprocess_image(x, seed=seed, apply_color_augmentation=False, apply_flip_augmentation=False))\n",
    "        labels_ds = tf.data.Dataset.from_tensor_slices(all_labels)\n",
    "        res = tf.data.Dataset.zip((paths_ds, labels_ds))\n",
    "        del paths_ds, labels_ds\n",
    "\n",
    "        res = res.batch(batch_size)\n",
    "        res = res.prefetch(buffer_size=AUTOTUNE)\n",
    "        visual_sets.append((visual_slide.name, all_paths, all_labels, res, int(np.ceil((num_cancer + num_normal) / batch_size))))\n",
    "    return visual_sets\n",
    "\n",
    "for test_slide in get_test_dataset(32, 2):\n",
    "    print(test_slide)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732 _ (14, 299, 299, 3)\r"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(a):\n",
    "    imgs, labels = x\n",
    "    print('{} _ {}\\r'.format(idx, imgs.shape), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset(batch_size, seed=None):\n",
    "    \"\"\"\n",
    "    Creates training minibatch for a single training epoch\n",
    "\n",
    "    Arguments:\n",
    "        batch_size      -   test set batch size\n",
    "        steps_per_epoch -   how many minibatches should be trained on during one epoch\n",
    "        seed            -   seed for random operations\n",
    "    \"\"\"\n",
    "    \n",
    "    if type_ == 'train':\n",
    "        load_dir = TRAIN_DIR\n",
    "        apply_color_augmentation = True\n",
    "        apply_flip_augmentation = True\n",
    "    elif type_ == 'valid':\n",
    "        load_dir = VALID_DIR\n",
    "        apply_color_augmentation = False\n",
    "        apply_flip_augmentation = False\n",
    "    else:\n",
    "        raise ValueError('Unrecognized \\'type\\' value: \\'{}\\''.format(type_))\n",
    "\n",
    "    # Get list of cancer tile directories\n",
    "    cancer_datasets = []\n",
    "    for cancer_slide in load_dir.glob('*/cancer'):\n",
    "        paths = [str(path_) for path_ in cancer_slide.iterdir()]\n",
    "        ds_paths = tf.data.Dataset.from_tensor_slices(paths)        \n",
    "        ds_labels = tf.data.Dataset.from_tensor_slices([1] * len(paths))\n",
    "        ds = tf.data.Dataset.zip((ds_paths, ds_labels))\n",
    "        ds = ds.apply(tf.data.experimental.shuffle_and_repeat(len(paths), count=None, seed=seed))\n",
    "        cancer_datasets.append(ds)\n",
    "        \n",
    "    # Get list of normal tile directories\n",
    "    normal_datasets = []\n",
    "    for normal_slide in load_dir.glob('*/normal'):\n",
    "        paths = [str(path_) for path_ in normal_slide.iterdir()]\n",
    "        ds_paths = tf.data.Dataset.from_tensor_slices(paths)        \n",
    "        ds_labels = tf.data.Dataset.from_tensor_slices([0] * len(paths))\n",
    "        ds = tf.data.Dataset.zip((ds_paths, ds_labels))\n",
    "        ds = ds.apply(tf.data.experimental.shuffle_and_repeat(len(paths), count=None, seed=seed))\n",
    "        normal_datasets.append(ds)\n",
    "\n",
    "    # Calculate sampling distribution on datasets\n",
    "    per_cancer_proba = CANCER_SAMPLE_PROBA / len(cancer_datasets)\n",
    "    per_normal_proba = (1 - CANCER_SAMPLE_PROBA) / len(normal_datasets)\n",
    "    proba_vector = ([per_cancer_proba] * len(cancer_datasets)) + ([per_normal_proba] * len(normal_datasets))\n",
    "\n",
    "    # Sample tiles\n",
    "    full_ds = tf.data.experimental.sample_from_datasets(cancer_datasets + normal_datasets, weights=proba_vector, seed=seed)\n",
    "    full_ds = full_ds.apply(tf.data.experimental.map_and_batch(lambda x, y: (_load_and_preprocess_image(x, seed=seed, apply_color_augmentation=apply_color_augmentation, apply_flip_augmentation=apply_flip_augmentation), y), batch_size=batch_size))\n",
    "    full_ds = full_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return full_ds, steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds, _ = get_dataset(32, None, type_='valid', seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier\n"
     ]
    }
   ],
   "source": [
    "print('Binary Classifier')\n",
    "output_activation = tf.nn.sigmoid\n",
    "loss_fn = tf.keras.losses.binary_crossentropy\n",
    "metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
    "         tf.keras.metrics.Precision(), \n",
    "         tf.keras.metrics.Recall()]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=8, kernel_size=5, \n",
    "                                strides=4, activation=tf.nn.relu, \n",
    "                                input_shape=(299, 299, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(rate=0.5),\n",
    "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1, activation=output_activation)\n",
    "])\n",
    "\n",
    "model.compile(loss=loss_fn, metrics=metrics, optimizer=tf.train.RMSPropOptimizer(learning_rate=0.002, \n",
    "                                                                                    decay=0.001, \n",
    "                                                                                    momentum=0.001, \n",
    "                                                                                    epsilon=0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.6851 - binary_accuracy: 0.5546 - precision: 0.5529 - recall: 0.5871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbd05f3fa90>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(full_ds, steps_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img):\n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.uint8)\n",
    "    img = tf.squeeze(img)\n",
    "    return Image.fromarray(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_and_preprocess_image(path, seed, apply_flip_augmentation=True, apply_color_augmentation=True):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    return _preprocess_image(image, apply_color_augmentation, apply_flip_augmentation, seed=seed)\n",
    "\n",
    "\n",
    "def _preprocess_image(image, apply_color_augmentation=True, apply_flip_augmentation=True, seed=None, width=299, height=299):\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [width, height])\n",
    "    image = image / 255.0  # normalize to [0,1] range\n",
    "    if apply_flip_augmentation:\n",
    "        image = _flip_rotate_augmentation(image, seed)\n",
    "\n",
    "    if apply_color_augmentation:\n",
    "        image = _color_augmentation(image, seed)\n",
    "    image = 2*image-1       # rescale to [-1,1]\n",
    "    return image\n",
    "\n",
    "\n",
    "def _color_augmentation(x, seed):\n",
    "    x = tf.image.random_hue(x, 0.04, seed)\n",
    "    x = tf.image.random_saturation(x, 0, 0.25, seed)\n",
    "    x = tf.image.random_brightness(x, 64/255, seed)\n",
    "    x = tf.image.random_contrast(x, 0, 0.75, seed)\n",
    "    x = tf.clip_by_value(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _flip_rotate_augmentation(x, seed):\n",
    "    x = tf.image.random_flip_left_right(x, seed)\n",
    "    rotation = np.random.choice([0, 1, 2, 3])\n",
    "    x = tf.image.rot90(x, k=rotation)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
