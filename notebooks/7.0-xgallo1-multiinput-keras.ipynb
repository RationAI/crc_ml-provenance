{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "from tensorflow import keras\n",
    "sess = tf.Session(config=config)\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import openslide as ops\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "DIR = '/home/matejg/Project/crc_ml/data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_model(context_size=3):\n",
    "    inputs = [keras.layers.Input(shape=(96,96,3)) for _ in range(context_size*context_size)]\n",
    "\n",
    "    x = keras.applications.NASNetMobile(include_top=False, input_tensor=tf.keras.layers.Input(shape=(96,96,3)), weights='imagenet') \n",
    "    gmax = tf.keras.layers.GlobalMaxPooling2D()\n",
    "    gavg = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    flat = tf.keras.layers.Flatten()\n",
    "    con = tf.keras.layers.Concatenate(axis=-1)\n",
    "    drop = tf.keras.layers.Dropout(0.5)\n",
    "    out = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    outs = []\n",
    "    for inp in inputs:\n",
    "        f = x(inp)\n",
    "        f1 = gmax(f)\n",
    "        f2 = gavg(f)\n",
    "        f3 = flat(f)\n",
    "        f = con([f1,f2,f3])\n",
    "        f = drop(f)\n",
    "        f = out(f)\n",
    "        outs.append(f)\n",
    "        \n",
    "    out = keras.layers.Concatenate(axis=-1)(outs)\n",
    "    out = keras.layers.Dense(1, activation='sigmoid')(out)\n",
    "    model = keras.Model(inputs, out)\n",
    "    return model\n",
    "\n",
    "def create_model():\n",
    "    inputs = tf.keras.layers.Input((96,96,3))\n",
    "    nasnet_model = tf.keras.applications.nasnet.NASNetMobile(include_top=False, input_tensor=inputs, weights='imagenet')\n",
    "    nasnet_model.trainable=True\n",
    "\n",
    "    x = nasnet_model(inputs)\n",
    "    out1 = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "    out2 = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    out3 = tf.keras.layers.Flatten()(x)\n",
    "    out = tf.keras.layers.Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = tf.keras.layers.Dropout(0.5)(out)\n",
    "    out = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, name=\"3_\")(out)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_macrotile_mask(slide_name):\n",
    "    RAW_WSI_DIR = '/home/matejg/Project/crc_ml/data/raw/Prostata/'\n",
    "    SCALE_FACTOR = 1\n",
    "    OUTPUT_DIR = '/home/matejg/macrotiles/masks/'\n",
    "    \n",
    "    slide_file_no_ext = Path(RAW_WSI_DIR + slide_name)\n",
    "    slide = ops.open_slide(str(slide_file_no_ext.with_suffix('.mrxs')))\n",
    "    \n",
    "    level = slide.get_best_level_for_downsample(SCALE_FACTOR)\n",
    "    \n",
    "    rectangle_image = Image.new('L', size=slide.level_dimensions[level], color='BLACK')\n",
    "    rectangle_draw = ImageDraw.Draw(rectangle_image)\n",
    "    \n",
    "    tiles = get_tiles_for_slide_all(slide_name)\n",
    "    tiles = set(['-'.join(path.rsplit('-', 7)[:4]) for path in tiles])\n",
    "    tiles = list(filter(lambda x: check_context(x, 3, tiles), tiles))\n",
    "    \n",
    "    for tile in tiles:\n",
    "        _, _, r, c = tile.rsplit('-', 3)\n",
    "        r = int(r[1:])\n",
    "        c = int(c[1:])\n",
    "        x = ((c-1)*299+1)//SCALE_FACTOR\n",
    "        y = ((r-1)*299+1)//SCALE_FACTOR\n",
    "        size = 299 // SCALE_FACTOR\n",
    "        rectangle_draw.rectangle([(x, y), (x+size, y+size)], fill=(255))\n",
    "    \n",
    "    fig_filepath = OUTPUT_DIR + slide_name + '-macrotile-mask.png'\n",
    "    rectangle_image.save(fp=fig_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates giga-pixel macrotile mask\n",
    "\"\"\"\n",
    "for slide in slide_name_iterator_all():\n",
    "    create_macrotile_mask(slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_macrotile_image(slide_name):\n",
    "    RAW_WSI_DIR = '/home/matejg/Project/crc_ml/data/raw/Prostata/'\n",
    "    SCALE_FACTOR = 40\n",
    "    OUTPUT_DIR = '/home/matejg/macrotiles/'\n",
    "\n",
    "    slide_file_no_ext = Path(RAW_WSI_DIR + slide_name)\n",
    "    slide = ops.open_slide(str(slide_file_no_ext.with_suffix('.mrxs')))\n",
    "\n",
    "    level = slide.get_best_level_for_downsample(SCALE_FACTOR)\n",
    "\n",
    "    large_w, large_h = slide.dimensions\n",
    "    small_w = np.floor(large_w / SCALE_FACTOR).astype(int)\n",
    "    small_h = np.floor(large_h / SCALE_FACTOR).astype(int)\n",
    "\n",
    "    wsi_image = slide.read_region((0,0), level, slide.level_dimensions[level])\n",
    "    wsi_image = wsi_image.convert('RGBA')\n",
    "    wsi_image = wsi_image.resize((small_w, small_h))\n",
    "    wsi_draw = ImageDraw.Draw(wsi_image)\n",
    "\n",
    "    tiles = get_tiles_for_slide_all(slide_name)\n",
    "    tiles = set(['-'.join(path.rsplit('-', 7)[:4]) for path in tiles])\n",
    "    tiles = list(filter(lambda x: check_context(x, 3, tiles), tiles))\n",
    "\n",
    "    for tile in tiles:\n",
    "        _, _, r, c = tile.rsplit('-', 3)\n",
    "        r = int(r[1:])\n",
    "        c = int(c[1:])\n",
    "        x = ((c-1)*299+1)//SCALE_FACTOR\n",
    "        y = ((r-1)*299+1)//SCALE_FACTOR\n",
    "        size = 299 // SCALE_FACTOR\n",
    "        wsi_draw.rectangle([(x, y), (x+size, y+size)], fill=(255,255,0,175))\n",
    "\n",
    "    fig_filepath = OUTPUT_DIR + slide_name + '-macrotile.png'\n",
    "    wsi_image.save(fp=fig_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates giga-pixel macrotile images\n",
    "\"\"\"\n",
    "for slide in slide_name_iterator_all():\n",
    "    create_macrotile_image(slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "def get_augmenter():\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            iaa.Fliplr(0.5),  # horizontally flip 50% of all images\n",
    "            iaa.Flipud(0.2),  # vertically flip 20% of all images\n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                # scale images to 80-120% of their size, individually per axis\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},  # translate by -20 to +20 percent (per axis)\n",
    "                rotate=(-10, 10),  # rotate by -45 to +45 degrees\n",
    "                shear=(-5, 5),  # shear by -16 to +16 degrees\n",
    "                order=[0, 1],  # use nearest neighbour or bilinear interpolation (fast)\n",
    "                cval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n",
    "                mode=ia.ALL  # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            )),\n",
    "            # execute 0 to 5 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 5),\n",
    "                    [\n",
    "                        sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))),\n",
    "                        # convert images into their superpixel representation\n",
    "                        iaa.OneOf([\n",
    "                            iaa.GaussianBlur((0, 1.0)),  # blur images with a sigma between 0 and 3.0\n",
    "                            iaa.AverageBlur(k=(3, 5)),\n",
    "                            # blur image using local means with kernel sizes between 2 and 7\n",
    "                            iaa.MedianBlur(k=(3, 5)),\n",
    "                            # blur image using local medians with kernel sizes between 2 and 7\n",
    "                        ]),\n",
    "                        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)),  # sharpen images\n",
    "                        iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),  # emboss images\n",
    "                        # search either for all edges or for directed edges,\n",
    "                        # blend the result with the original image using a blobby mask\n",
    "                        iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                            iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                            iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                        ])),\n",
    "                        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01 * 255), per_channel=0.5),\n",
    "                        # add gaussian noise to images\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Dropout((0.01, 0.05), per_channel=0.5),  # randomly remove up to 10% of the pixels\n",
    "                            iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
    "                        ]),\n",
    "                        iaa.Invert(0.01, per_channel=True),  # invert color channels\n",
    "                        iaa.Add((-2, 2), per_channel=0.5),\n",
    "                        # change brightness of images (by -10 to 10 of original value)\n",
    "                        iaa.AddToHueAndSaturation((-1, 1)),  # change hue and saturation\n",
    "                        # either change the brightness of the whole image (sometimes\n",
    "                        # per channel) or change the brightness of subareas\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                            iaa.FrequencyNoiseAlpha(\n",
    "                                exponent=(-1, 0),\n",
    "                                first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
    "                                second=iaa.ContrastNormalization((0.9, 1.1))\n",
    "                            )\n",
    "                        ]),\n",
    "                        sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)),\n",
    "                        # move pixels locally around (with random strengths)\n",
    "                        sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n",
    "                        # sometimes move parts of the image around\n",
    "                        sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                    ],\n",
    "                    random_order=True\n",
    "                    )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return seq\n",
    "\n",
    "def get_test_augmenter(augment_type):\n",
    "    seq = None\n",
    "    if augment_type == 'horizontal':\n",
    "        print('Horizontal augment.')\n",
    "        seq = iaa.Sequential([iaa.Fliplr(1)])\n",
    "    elif augment_type == 'vertical':\n",
    "        print('Vertical augment')\n",
    "        seq = iaa.Sequential([iaa.Flipud(1)])\n",
    "    elif augment_type == 'both':\n",
    "        print('Horizontal+Vertical augment')\n",
    "        seq = iaa.Sequential([iaa.Flipud(1), iaa.Fliplr(1)])\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_for_slide(tile_index, slide_name='*', split_type='train'):\n",
    "    tiles = get_tiles_for_slide(slide_name, split_type)\n",
    "    center_tiles = list(filter(lambda x: generate_context(x, 3, tile_index), tiles))\n",
    "    center_labels = [1 if tile.split('/')[9] == 'cancer' else 0 for tile in center_tiles]\n",
    "    \n",
    "    proba = {}\n",
    "    for k,v in Counter(center_labels).items():\n",
    "        proba[k] = 0.5/v\n",
    "    center_weights = [proba[label] for label in center_labels]\n",
    "    pd_data = pd.DataFrame({'filename': center_tiles, 'class': center_labels, 'weight': center_weights})\n",
    "    return pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles_for_slide(slide_name='*', split_type='train'):\n",
    "    if split_type == 'train':\n",
    "        part1 = glob.glob(DIR + 'train_slides/{}/*/*.png'.format(slide_name))\n",
    "        part2 = glob.glob(DIR + 'valid_slides/{}/*/*.png'.format(slide_name))\n",
    "    else:\n",
    "        part1 = glob.glob(DIR + 'test_slides/{}/*/*.png'.format(slide_name))\n",
    "        part2 = glob.glob(DIR + 'visual_slides/{}/*/*.png'.format(slide_name))\n",
    "    tiles = part1 + part2\n",
    "    return tiles\n",
    "\n",
    "def create_inverted_index(split_type='train'):\n",
    "    Tile = namedtuple('Tile', 'split_type slide_name label_name tile_name')\n",
    "    tiles = get_tiles_for_slide(split_type=split_type)\n",
    "    tile_index = defaultdict(dict)\n",
    "    for tile in tiles:\n",
    "        tile_parts = Tile(*Path(tile).parts[-4:])\n",
    "        row_col_id = ''.join(tile_parts.tile_name.rsplit('-', 7)[2:4])\n",
    "        tile_index[row_col_id][tile_parts.slide_name] = tile\n",
    "    return tile_index\n",
    "\n",
    "def generate_context(filename, context_size, tile_index):\n",
    "    \n",
    "    assert context_size % 2 == 1, 'context_size must be odd number'\n",
    "    \n",
    "    if context_size == 1:\n",
    "        return [filename]\n",
    "    \n",
    "    slide_name, _, row, col, *_ = os.path.basename(filename).rsplit('-', 7)\n",
    "    row = int(row[1:])\n",
    "    col = int(col[1:])\n",
    "    \n",
    "    # TODO: Rename all tiles\n",
    "    if not slide_name.startswith('P-'):\n",
    "        slide_name = 'P-' + slide_name\n",
    "        \n",
    "    row_col_id = lambda r, c: 'r{}c{}'.format(r,c)\n",
    "\n",
    "    context_limit = (context_size - 1) // 2\n",
    "    context_range = range(-context_limit, context_limit+1)\n",
    "    \n",
    "    context = []\n",
    "    try:\n",
    "        for r_offset in context_range:\n",
    "            for c_offset in context_range:\n",
    "                new_r = row + r_offset\n",
    "                new_c = col + c_offset\n",
    "                context_tile = tile_index[row_col_id(new_r, new_c)][slide_name]\n",
    "                context.append(context_tile)\n",
    "    except KeyError:\n",
    "        #print('Tiles {} for slide {} not found.'.format(row_col_id(new_r, new_c), slide_name))\n",
    "        return []\n",
    "                \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_split(tile_index, valid_ratio=0.03, slide_name='*', split_type='train'):\n",
    "    pd_data = get_dataset_for_slide(tile_index, slide_name, split_type)\n",
    "    train_df, valid_df = train_test_split(pd_data, test_size=valid_ratio)\n",
    "\n",
    "    valid_df = valid_df.copy()\n",
    "    valid_df['weight'] = valid_df['weight'].div(valid_df['weight'].sum(axis=0), axis=0)\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    train_df['weight'] = train_df['weight'].div(train_df['weight'].sum(axis=0), axis=0)\n",
    "    \n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TRAIN FEED \"\"\"\n",
    "def get_random_batch(tile_index, pd_data, batch_size=32):\n",
    "    seq = get_augmenter()\n",
    "    \n",
    "    while True:\n",
    "        batch = pd_data.sample(n=batch_size, replace=True, weights=pd_data['weight'])\n",
    "        batch_context = [generate_context(fn, 1, tile_index) for fn in batch.filename]\n",
    "        batch_context = np.array([np.array([cv2.resize(cv2.imread(im), dsize=(96,96), interpolation=cv2.INTER_CUBIC) for im in im_batch]) for im_batch in batch_context])\n",
    "        batch_context = batch_context.transpose((1,0,2,3,4))\n",
    "        batch_context = [tf.keras.applications.nasnet.preprocess_input(seq.augment_images(batch)) for batch in batch_context]\n",
    "        yield batch_context, batch['class'].values\n",
    "\n",
    "        \n",
    "\"\"\" TEST FEED \"\"\"\n",
    "def _chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def _divide_round_up(n, d):\n",
    "    return (n + (d - 1))//d\n",
    "\n",
    "def get_sequential_batch(tile_index, pd_data, augment=None, batch_size=32):\n",
    "    \n",
    "    if augment in ['horizontal','vertical','both']:\n",
    "        seq = get_test_augmenter(augment)\n",
    "\n",
    "    #pd_data = get_dataset_for_slide(tile_index, slide_name, split_type)\n",
    "    \n",
    "    while True:                \n",
    "        for batch in _chunker(pd_data, batch_size):\n",
    "            batch_context = [generate_context(fn, 3, tile_index) for fn in batch.filename]\n",
    "            batch_context = np.array([np.array([cv2.resize(cv2.imread(im), dsize=(96,96), interpolation=cv2.INTER_CUBIC) for im in im_batch]) for im_batch in batch_context])\n",
    "            batch_context = batch_context.transpose((1,0,2,3,4))\n",
    "            if augment:\n",
    "                batch_context = [tf.keras.applications.nasnet.preprocess_input(seq.augment_images(batch)) for batch in batch_context]\n",
    "            else:\n",
    "                batch_context = [tf.keras.applications.nasnet.preprocess_input(batch) for batch in batch_context]\n",
    "            yield batch_context, batch['class'].values\n",
    "            \n",
    "def get_sequential_metadata(tile_index, slide_name='*', split_type='test', batch_size=32):\n",
    "    pd_data = get_dataset_for_slide(tile_index, slide_name, split_type)\n",
    "    return _divide_round_up(len(pd_data), batch_size), pd_data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_tile_index = create_inverted_index()\n",
    "_test_tile_index = create_inverted_index('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true):\n",
    "    quality_metrics = {}\n",
    "\n",
    "    # BINARY CROSSENTROPY\n",
    "    m = tf.keras.losses.BinaryCrossentropy()\n",
    "    quality_metrics['loss'] = m(y_true, y_pred)\n",
    "\n",
    "    # BINARY ACCURACY\n",
    "    m = tf.keras.metrics.BinaryAccuracy()\n",
    "    m.update_state(y_true, y_pred)\n",
    "    quality_metrics['accuracy'] = m.result().numpy()\n",
    "\n",
    "    # PRECISION\n",
    "    m = tf.keras.metrics.Precision()\n",
    "    m.update_state(y_true, y_pred)\n",
    "    quality_metrics['precision'] = m.result().numpy()\n",
    "\n",
    "    # RECALL\n",
    "    m = tf.keras.metrics.Recall()\n",
    "    m.update_state(y_true, y_pred)\n",
    "    quality_metrics['recall'] = m.result().numpy()\n",
    "\n",
    "    return quality_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tile_index, steps, train_df, valid_df, batch_size=32, epochs=1, callbacks=[]):\n",
    "    valid_steps = _divide_round_up(len(valid_df), batch_size)\n",
    "    \n",
    "    model.fit_generator(generator=get_random_batch(tile_index, train_df, batch_size),\n",
    "                        validation_data=get_sequential_batch(tile_index, valid_df, batch_size=batch_size),\n",
    "                        steps_per_epoch=steps, \n",
    "                        validation_steps=valid_steps,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1, \n",
    "                        epochs=epochs)\n",
    "\n",
    "def test(model, tile_index, batch_size=32):\n",
    "    predicts = 1\n",
    "    steps, labels = get_sequential_metadata(tile_index, batch_size=batch_size)\n",
    "    test_df = get_dataset_for_slide(tile_index, '*', 'test')\n",
    "    for augment_type in [None, 'horizontal', 'vertical', 'both']:\n",
    "        predicts *= model.predict_generator(get_sequential_batch(tile_index, test_df, augment=augment_type, batch_size=batch_size), \n",
    "                                            steps=steps, verbose=1).ravel()\n",
    "\n",
    "    predicts = predicts ** 0.25\n",
    "    quality_metrics = calculate_metrics(predicts.ravel(), labels.ravel())\n",
    "    return quality_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 3, 3, 1056)   4269716     input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9504)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 11616)        0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 11616)        0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            11617       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,281,333\n",
      "Trainable params: 4,244,595\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Beginning training...\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "192/192 [==============================] - 137s 713ms/step - loss: 0.9834 - binary_accuracy: 0.6821 - precision_1: 0.1742 - recall_1: 0.8498\n",
      "\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.68212, saving model to /home/matejg/nasnet.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7fa7fd1bc278>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "2000/2000 [==============================] - 861s 430ms/step - loss: 0.4819 - binary_accuracy: 0.7747 - precision_1: 0.7784 - recall_1: 0.7706 - val_loss: 0.9834 - val_binary_accuracy: 0.6821 - val_precision_1: 0.1742 - val_recall_1: 0.8498\n",
      "Epoch 2/7\n",
      "192/192 [==============================] - 128s 669ms/step - loss: 0.2918 - binary_accuracy: 0.8919 - precision_1: 0.3923 - recall_1: 0.7661\n",
      "\n",
      "Epoch 00002: val_binary_accuracy improved from 0.68212 to 0.89192, saving model to /home/matejg/nasnet.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7fa7fd1bc278>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "2000/2000 [==============================] - 707s 353ms/step - loss: 0.3621 - binary_accuracy: 0.8367 - precision_1: 0.8385 - recall_1: 0.8333 - val_loss: 0.2918 - val_binary_accuracy: 0.8919 - val_precision_1: 0.3923 - val_recall_1: 0.7661\n",
      "Epoch 3/7\n",
      "192/192 [==============================] - 128s 667ms/step - loss: 0.2083 - binary_accuracy: 0.9260 - precision_1: 0.5090 - recall_1: 0.7854\n",
      "\n",
      "Epoch 00003: val_binary_accuracy improved from 0.89192 to 0.92604, saving model to /home/matejg/nasnet.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7fa7fd1bc278>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "2000/2000 [==============================] - 710s 355ms/step - loss: 0.3221 - binary_accuracy: 0.8585 - precision_1: 0.8617 - recall_1: 0.8561 - val_loss: 0.2083 - val_binary_accuracy: 0.9260 - val_precision_1: 0.5090 - val_recall_1: 0.7854\n",
      "Epoch 4/7\n",
      "192/192 [==============================] - 128s 665ms/step - loss: 0.1973 - binary_accuracy: 0.9244 - precision_1: 0.5020 - recall_1: 0.7918\n",
      "\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 708s 354ms/step - loss: 0.2979 - binary_accuracy: 0.8701 - precision_1: 0.8726 - recall_1: 0.8653 - val_loss: 0.1973 - val_binary_accuracy: 0.9244 - val_precision_1: 0.5020 - val_recall_1: 0.7918\n",
      "Epoch 5/7\n",
      "192/192 [==============================] - 127s 663ms/step - loss: 0.2882 - binary_accuracy: 0.9020 - precision_1: 0.4264 - recall_1: 0.8326\n",
      "\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 711s 356ms/step - loss: 0.2808 - binary_accuracy: 0.8811 - precision_1: 0.8853 - recall_1: 0.8744 - val_loss: 0.2882 - val_binary_accuracy: 0.9020 - val_precision_1: 0.4264 - val_recall_1: 0.8326\n",
      "Epoch 6/7\n",
      "192/192 [==============================] - 129s 669ms/step - loss: 0.2312 - binary_accuracy: 0.9122 - precision_1: 0.4579 - recall_1: 0.8412\n",
      "\n",
      "Epoch 00006: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 711s 355ms/step - loss: 0.2626 - binary_accuracy: 0.8880 - precision_1: 0.8910 - recall_1: 0.8814 - val_loss: 0.2312 - val_binary_accuracy: 0.9122 - val_precision_1: 0.4579 - val_recall_1: 0.8412\n",
      "Epoch 7/7\n",
      "192/192 [==============================] - 129s 671ms/step - loss: 0.3111 - binary_accuracy: 0.8779 - precision_1: 0.3714 - recall_1: 0.8734\n",
      "\n",
      "Epoch 00007: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 701s 351ms/step - loss: 0.2516 - binary_accuracy: 0.8934 - precision_1: 0.8929 - recall_1: 0.8924 - val_loss: 0.3111 - val_binary_accuracy: 0.8779 - val_precision_1: 0.3714 - val_recall_1: 0.8734\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 314s 679ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 298s 644ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 294s 637ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 302s 654ms/step\n",
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning testing...\n",
      "462/462 [==============================] - 292s 631ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 300s 648ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 295s 638ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 300s 649ms/step\n",
      "Beginning training...\n",
      "Epoch 1/7\n",
      "192/192 [==============================] - 128s 666ms/step - loss: 0.2032 - binary_accuracy: 0.9244 - precision_1: 0.5020 - recall_1: 0.8090\n",
      "\n",
      "Epoch 00001: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 696s 348ms/step - loss: 0.3023 - binary_accuracy: 0.8699 - precision_1: 0.8716 - recall_1: 0.8682 - val_loss: 0.2032 - val_binary_accuracy: 0.9244 - val_precision_1: 0.5020 - val_recall_1: 0.8090\n",
      "Epoch 2/7\n",
      "192/192 [==============================] - 128s 668ms/step - loss: 0.2346 - binary_accuracy: 0.9099 - precision_1: 0.4511 - recall_1: 0.8519\n",
      "\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 695s 347ms/step - loss: 0.2756 - binary_accuracy: 0.8819 - precision_1: 0.8831 - recall_1: 0.8794 - val_loss: 0.2346 - val_binary_accuracy: 0.9099 - val_precision_1: 0.4511 - val_recall_1: 0.8519\n",
      "Epoch 3/7\n",
      "192/192 [==============================] - 128s 667ms/step - loss: 0.1911 - binary_accuracy: 0.9234 - precision_1: 0.4980 - recall_1: 0.8197\n",
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 699s 349ms/step - loss: 0.2654 - binary_accuracy: 0.8877 - precision_1: 0.8878 - recall_1: 0.8860 - val_loss: 0.1911 - val_binary_accuracy: 0.9234 - val_precision_1: 0.4980 - val_recall_1: 0.8197\n",
      "Epoch 4/7\n",
      "192/192 [==============================] - 128s 668ms/step - loss: 0.2737 - binary_accuracy: 0.8942 - precision_1: 0.4086 - recall_1: 0.8734\n",
      "\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 706s 353ms/step - loss: 0.2497 - binary_accuracy: 0.8931 - precision_1: 0.8954 - recall_1: 0.8912 - val_loss: 0.2737 - val_binary_accuracy: 0.8942 - val_precision_1: 0.4086 - val_recall_1: 0.8734\n",
      "Epoch 5/7\n",
      "192/192 [==============================] - 129s 671ms/step - loss: 0.2386 - binary_accuracy: 0.9019 - precision_1: 0.4315 - recall_1: 0.9120\n",
      "\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.92604\n",
      "2000/2000 [==============================] - 695s 348ms/step - loss: 0.2432 - binary_accuracy: 0.8970 - precision_1: 0.8976 - recall_1: 0.8969 - val_loss: 0.2386 - val_binary_accuracy: 0.9019 - val_precision_1: 0.4315 - val_recall_1: 0.9120\n",
      "Epoch 6/7\n",
      "192/192 [==============================] - 128s 668ms/step - loss: 0.1244 - binary_accuracy: 0.9569 - precision_1: 0.6996 - recall_1: 0.7597\n",
      "\n",
      "Epoch 00006: val_binary_accuracy improved from 0.92604 to 0.95690, saving model to /home/matejg/nasnet.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7fa7fd1bc278>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "2000/2000 [==============================] - 701s 351ms/step - loss: 0.2328 - binary_accuracy: 0.9014 - precision_1: 0.9025 - recall_1: 0.9002 - val_loss: 0.1244 - val_binary_accuracy: 0.9569 - val_precision_1: 0.6996 - val_recall_1: 0.7597\n",
      "Epoch 7/7\n",
      "192/192 [==============================] - 127s 664ms/step - loss: 0.2182 - binary_accuracy: 0.9207 - precision_1: 0.4883 - recall_1: 0.8927\n",
      "\n",
      "Epoch 00007: val_binary_accuracy did not improve from 0.95690\n",
      "2000/2000 [==============================] - 714s 357ms/step - loss: 0.2254 - binary_accuracy: 0.9059 - precision_1: 0.9063 - recall_1: 0.9056 - val_loss: 0.2182 - val_binary_accuracy: 0.9207 - val_precision_1: 0.4883 - val_recall_1: 0.8927\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 295s 639ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 302s 655ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 297s 642ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 303s 657ms/step\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 294s 636ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 304s 658ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 298s 644ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 304s 659ms/step\n",
      "Beginning training...\n",
      "Epoch 1/7\n",
      "192/192 [==============================] - 128s 666ms/step - loss: 0.2107 - binary_accuracy: 0.9180 - precision_1: 0.4793 - recall_1: 0.8927\n",
      "\n",
      "Epoch 00001: val_binary_accuracy did not improve from 0.95690\n",
      "2000/2000 [==============================] - 706s 353ms/step - loss: 0.2283 - binary_accuracy: 0.9044 - precision_1: 0.9049 - recall_1: 0.9048 - val_loss: 0.2107 - val_binary_accuracy: 0.9180 - val_precision_1: 0.4793 - val_recall_1: 0.8927\n",
      "Epoch 2/7\n",
      "192/192 [==============================] - 127s 663ms/step - loss: 0.1913 - binary_accuracy: 0.9229 - precision_1: 0.4963 - recall_1: 0.8605\n",
      "\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.95690\n",
      "2000/2000 [==============================] - 706s 353ms/step - loss: 0.2218 - binary_accuracy: 0.9074 - precision_1: 0.9068 - recall_1: 0.9072 - val_loss: 0.1913 - val_binary_accuracy: 0.9229 - val_precision_1: 0.4963 - val_recall_1: 0.8605\n",
      "Epoch 3/7\n",
      "192/192 [==============================] - 127s 660ms/step - loss: 0.1964 - binary_accuracy: 0.9273 - precision_1: 0.5134 - recall_1: 0.8648\n",
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.95690\n",
      "2000/2000 [==============================] - 706s 353ms/step - loss: 0.2173 - binary_accuracy: 0.9092 - precision_1: 0.9077 - recall_1: 0.9118 - val_loss: 0.1964 - val_binary_accuracy: 0.9273 - val_precision_1: 0.5134 - val_recall_1: 0.8648\n",
      "Epoch 4/7\n",
      "192/192 [==============================] - 127s 661ms/step - loss: 0.1172 - binary_accuracy: 0.9597 - precision_1: 0.6995 - recall_1: 0.8240\n",
      "\n",
      "Epoch 00004: val_binary_accuracy improved from 0.95690 to 0.95967, saving model to /home/matejg/nasnet.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7fa7fd1bc278>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "2000/2000 [==============================] - 708s 354ms/step - loss: 0.2140 - binary_accuracy: 0.9107 - precision_1: 0.9107 - recall_1: 0.9100 - val_loss: 0.1172 - val_binary_accuracy: 0.9597 - val_precision_1: 0.6995 - val_recall_1: 0.8240\n",
      "Epoch 5/7\n",
      "192/192 [==============================] - 127s 664ms/step - loss: 0.2165 - binary_accuracy: 0.9187 - precision_1: 0.4816 - recall_1: 0.8970\n",
      "\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 721s 360ms/step - loss: 0.2058 - binary_accuracy: 0.9146 - precision_1: 0.9136 - recall_1: 0.9157 - val_loss: 0.2165 - val_binary_accuracy: 0.9187 - val_precision_1: 0.4816 - val_recall_1: 0.8970\n",
      "Epoch 6/7\n",
      "192/192 [==============================] - 128s 666ms/step - loss: 0.1245 - binary_accuracy: 0.9576 - precision_1: 0.6776 - recall_1: 0.8433\n",
      "\n",
      "Epoch 00006: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 699s 349ms/step - loss: 0.2055 - binary_accuracy: 0.9134 - precision_1: 0.9119 - recall_1: 0.9150 - val_loss: 0.1245 - val_binary_accuracy: 0.9576 - val_precision_1: 0.6776 - val_recall_1: 0.8433\n",
      "Epoch 7/7\n",
      "192/192 [==============================] - 126s 656ms/step - loss: 0.1587 - binary_accuracy: 0.9381 - precision_1: 0.5602 - recall_1: 0.8691\n",
      "\n",
      "Epoch 00007: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 699s 349ms/step - loss: 0.2014 - binary_accuracy: 0.9162 - precision_1: 0.9139 - recall_1: 0.9187 - val_loss: 0.1587 - val_binary_accuracy: 0.9381 - val_precision_1: 0.5602 - val_recall_1: 0.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning testing...\n",
      "462/462 [==============================] - 292s 632ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 301s 652ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 294s 636ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 302s 655ms/step\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 296s 641ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 302s 654ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 297s 643ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 300s 650ms/step\n",
      "Beginning training...\n",
      "Epoch 1/7\n",
      "192/192 [==============================] - 127s 664ms/step - loss: 0.3541 - binary_accuracy: 0.8691 - precision_1: 0.3591 - recall_1: 0.9185\n",
      "\n",
      "Epoch 00001: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 712s 356ms/step - loss: 0.2051 - binary_accuracy: 0.9143 - precision_1: 0.9134 - recall_1: 0.9153 - val_loss: 0.3541 - val_binary_accuracy: 0.8691 - val_precision_1: 0.3591 - val_recall_1: 0.9185\n",
      "Epoch 2/7\n",
      "192/192 [==============================] - 129s 670ms/step - loss: 0.2342 - binary_accuracy: 0.9043 - precision_1: 0.4374 - recall_1: 0.8991\n",
      "\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 708s 354ms/step - loss: 0.2047 - binary_accuracy: 0.9150 - precision_1: 0.9133 - recall_1: 0.9167 - val_loss: 0.2342 - val_binary_accuracy: 0.9043 - val_precision_1: 0.4374 - val_recall_1: 0.8991\n",
      "Epoch 3/7\n",
      "192/192 [==============================] - 129s 670ms/step - loss: 0.1232 - binary_accuracy: 0.9589 - precision_1: 0.6938 - recall_1: 0.8219\n",
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 703s 352ms/step - loss: 0.2011 - binary_accuracy: 0.9168 - precision_1: 0.9149 - recall_1: 0.9194 - val_loss: 0.1232 - val_binary_accuracy: 0.9589 - val_precision_1: 0.6938 - val_recall_1: 0.8219\n",
      "Epoch 4/7\n",
      "192/192 [==============================] - 128s 664ms/step - loss: 0.1751 - binary_accuracy: 0.9350 - precision_1: 0.5457 - recall_1: 0.8712\n",
      "\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 714s 357ms/step - loss: 0.1953 - binary_accuracy: 0.9192 - precision_1: 0.9176 - recall_1: 0.9215 - val_loss: 0.1751 - val_binary_accuracy: 0.9350 - val_precision_1: 0.5457 - val_recall_1: 0.8712\n",
      "Epoch 5/7\n",
      "192/192 [==============================] - 129s 673ms/step - loss: 0.1199 - binary_accuracy: 0.9533 - precision_1: 0.6433 - recall_1: 0.8670\n",
      "\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 712s 356ms/step - loss: 0.1964 - binary_accuracy: 0.9186 - precision_1: 0.9157 - recall_1: 0.9213 - val_loss: 0.1199 - val_binary_accuracy: 0.9533 - val_precision_1: 0.6433 - val_recall_1: 0.8670\n",
      "Epoch 6/7\n",
      "192/192 [==============================] - 127s 663ms/step - loss: 0.1770 - binary_accuracy: 0.9291 - precision_1: 0.5193 - recall_1: 0.9249\n",
      "\n",
      "Epoch 00006: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 704s 352ms/step - loss: 0.1941 - binary_accuracy: 0.9198 - precision_1: 0.9163 - recall_1: 0.9237 - val_loss: 0.1770 - val_binary_accuracy: 0.9291 - val_precision_1: 0.5193 - val_recall_1: 0.9249\n",
      "Epoch 7/7\n",
      "192/192 [==============================] - 128s 669ms/step - loss: 0.2865 - binary_accuracy: 0.8820 - precision_1: 0.3848 - recall_1: 0.9206\n",
      "\n",
      "Epoch 00007: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 709s 354ms/step - loss: 0.1855 - binary_accuracy: 0.9234 - precision_1: 0.9226 - recall_1: 0.9247 - val_loss: 0.2865 - val_binary_accuracy: 0.8820 - val_precision_1: 0.3848 - val_recall_1: 0.9206\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 294s 637ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 301s 651ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 297s 642ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 303s 655ms/step\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 295s 639ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 302s 653ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 297s 643ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 304s 658ms/step\n",
      "Beginning training...\n",
      "Epoch 1/7\n",
      "192/192 [==============================] - 127s 660ms/step - loss: 0.2749 - binary_accuracy: 0.8854 - precision_1: 0.3933 - recall_1: 0.9335\n",
      "\n",
      "Epoch 00001: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 704s 352ms/step - loss: 0.2075 - binary_accuracy: 0.9137 - precision_1: 0.9119 - recall_1: 0.9142 - val_loss: 0.2749 - val_binary_accuracy: 0.8854 - val_precision_1: 0.3933 - val_recall_1: 0.9335\n",
      "Epoch 2/7\n",
      "192/192 [==============================] - 129s 671ms/step - loss: 0.1507 - binary_accuracy: 0.9417 - precision_1: 0.5793 - recall_1: 0.8541\n",
      "\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 708s 354ms/step - loss: 0.2076 - binary_accuracy: 0.9138 - precision_1: 0.9109 - recall_1: 0.9179 - val_loss: 0.1507 - val_binary_accuracy: 0.9417 - val_precision_1: 0.5793 - val_recall_1: 0.8541\n",
      "Epoch 3/7\n",
      "192/192 [==============================] - 129s 670ms/step - loss: 0.2252 - binary_accuracy: 0.9073 - precision_1: 0.4457 - recall_1: 0.8991\n",
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 701s 351ms/step - loss: 0.1989 - binary_accuracy: 0.9174 - precision_1: 0.9151 - recall_1: 0.9185 - val_loss: 0.2252 - val_binary_accuracy: 0.9073 - val_precision_1: 0.4457 - val_recall_1: 0.8991\n",
      "Epoch 4/7\n",
      "192/192 [==============================] - 129s 673ms/step - loss: 0.1522 - binary_accuracy: 0.9427 - precision_1: 0.5842 - recall_1: 0.8562\n",
      "\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 710s 355ms/step - loss: 0.1917 - binary_accuracy: 0.9218 - precision_1: 0.9191 - recall_1: 0.9239 - val_loss: 0.1522 - val_binary_accuracy: 0.9427 - val_precision_1: 0.5842 - val_recall_1: 0.8562\n",
      "Epoch 5/7\n",
      "192/192 [==============================] - 128s 668ms/step - loss: 0.1864 - binary_accuracy: 0.9318 - precision_1: 0.5313 - recall_1: 0.8734\n",
      "\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.95967\n",
      "2000/2000 [==============================] - 705s 352ms/step - loss: 0.1889 - binary_accuracy: 0.9208 - precision_1: 0.9183 - recall_1: 0.9235 - val_loss: 0.1864 - val_binary_accuracy: 0.9318 - val_precision_1: 0.5313 - val_recall_1: 0.8734\n",
      "Epoch 6/7\n",
      "192/192 [==============================] - 127s 664ms/step - loss: 0.1153 - binary_accuracy: 0.9620 - precision_1: 0.7084 - recall_1: 0.8498\n",
      "\n",
      "Epoch 00006: val_binary_accuracy improved from 0.95967 to 0.96196, saving model to /home/matejg/nasnet.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7fa7fd1bc278>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "2000/2000 [==============================] - 715s 357ms/step - loss: 0.1915 - binary_accuracy: 0.9211 - precision_1: 0.9191 - recall_1: 0.9235 - val_loss: 0.1153 - val_binary_accuracy: 0.9620 - val_precision_1: 0.7084 - val_recall_1: 0.8498\n",
      "Epoch 7/7\n",
      "192/192 [==============================] - 126s 656ms/step - loss: 0.1953 - binary_accuracy: 0.9300 - precision_1: 0.5233 - recall_1: 0.8927\n",
      "\n",
      "Epoch 00007: val_binary_accuracy did not improve from 0.96196\n",
      "2000/2000 [==============================] - 706s 353ms/step - loss: 0.1886 - binary_accuracy: 0.9227 - precision_1: 0.9200 - recall_1: 0.9270 - val_loss: 0.1953 - val_binary_accuracy: 0.9300 - val_precision_1: 0.5233 - val_recall_1: 0.8927\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 295s 639ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 302s 653ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 295s 639ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 305s 660ms/step\n",
      "Beginning testing...\n",
      "462/462 [==============================] - 295s 639ms/step\n",
      "Horizontal augment.\n",
      "462/462 [==============================] - 302s 655ms/step\n",
      "Vertical augment\n",
      "462/462 [==============================] - 296s 640ms/step\n",
      "Horizontal+Vertical augment\n",
      "462/462 [==============================] - 303s 656ms/step\n",
      "Beginning training...\n",
      "Epoch 1/7\n",
      "192/192 [==============================] - 129s 673ms/step - loss: 0.2124 - binary_accuracy: 0.9221 - precision_1: 0.4935 - recall_1: 0.9013\n",
      "\n",
      "Epoch 00001: val_binary_accuracy did not improve from 0.96196\n",
      "2000/2000 [==============================] - 710s 355ms/step - loss: 0.1929 - binary_accuracy: 0.9208 - precision_1: 0.9196 - recall_1: 0.9224 - val_loss: 0.2124 - val_binary_accuracy: 0.9221 - val_precision_1: 0.4935 - val_recall_1: 0.9013\n",
      "Epoch 2/7\n",
      "192/192 [==============================] - 127s 662ms/step - loss: 0.1224 - binary_accuracy: 0.9576 - precision_1: 0.6717 - recall_1: 0.8648\n",
      "\n",
      "Epoch 00002: val_binary_accuracy did not improve from 0.96196\n",
      "2000/2000 [==============================] - 711s 356ms/step - loss: 0.1809 - binary_accuracy: 0.9258 - precision_1: 0.9241 - recall_1: 0.9283 - val_loss: 0.1224 - val_binary_accuracy: 0.9576 - val_precision_1: 0.6717 - val_recall_1: 0.8648\n",
      "Epoch 3/7\n",
      "192/192 [==============================] - 128s 667ms/step - loss: 0.1261 - binary_accuracy: 0.9576 - precision_1: 0.6728 - recall_1: 0.8605\n",
      "\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.96196\n",
      "2000/2000 [==============================] - 707s 353ms/step - loss: 0.1805 - binary_accuracy: 0.9268 - precision_1: 0.9241 - recall_1: 0.9293 - val_loss: 0.1261 - val_binary_accuracy: 0.9576 - val_precision_1: 0.6728 - val_recall_1: 0.8605\n",
      "Epoch 4/7\n",
      "1491/2000 [=====================>........] - ETA: 2:25 - loss: 0.1855 - binary_accuracy: 0.9234 - precision_1: 0.9220 - recall_1: 0.9250"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = get_train_valid_split(_train_tile_index)\n",
    "\n",
    "print('Creating a model')\n",
    "model = create_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=tf.keras.losses.binary_crossentropy, metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "model.summary()\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint('/home/matejg/nasnet.ckpt', monitor='val_binary_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "experiments = {}\n",
    "for experiment in range(15):\n",
    "    print('Beginning training...')\n",
    "    train(model, _train_tile_index, 2000, train_df, valid_df, epochs=7, callbacks=[model_ckpt])\n",
    "    \n",
    "    print('Beginning testing...')\n",
    "    experiments['{}_late'.format(experiment)] = test(model, _test_tile_index)\n",
    "    \n",
    "    model.load_weights('/home/matejg/nasnet.ckpt')\n",
    "    print('Beginning testing...')\n",
    "    experiments['{}_early'.format(experiment)] = test(model, _test_tile_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_early: A: 0.7848% | P: 0.8141% | R: 0.7657%\n",
      "10_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "11_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "12_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "13_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "14_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "1_early: A: 0.7640% | P: 0.8719% | R: 0.6461%\n",
      "2_early: A: 0.7484% | P: 0.8534% | R: 0.6296%\n",
      "3_early: A: 0.7484% | P: 0.8534% | R: 0.6296%\n",
      "4_early: A: 0.7775% | P: 0.8406% | R: 0.7117%\n",
      "5_early: A: 0.7775% | P: 0.8406% | R: 0.7117%\n",
      "6_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "7_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "8_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "9_early: A: 0.7345% | P: 0.8760% | R: 0.5767%\n",
      "A_avg: 0.7474% | P_avg: 0.8639 | R_avg: 0.6190\n",
      "\n",
      "0_late: A: 0.7783% | P: 0.7689% | R: 0.8270%\n",
      "10_late: A: 0.7587% | P: 0.7345% | R: 0.8476%\n",
      "11_late: A: 0.7674% | P: 0.8335% | R: 0.6968%\n",
      "12_late: A: 0.7655% | P: 0.8044% | R: 0.7319%\n",
      "13_late: A: 0.7555% | P: 0.7699% | R: 0.7631%\n",
      "14_late: A: 0.7438% | P: 0.7532% | R: 0.7627%\n",
      "1_late: A: 0.7670% | P: 0.7683% | R: 0.7975%\n",
      "2_late: A: 0.7676% | P: 0.7815% | R: 0.7746%\n",
      "3_late: A: 0.7340% | P: 0.6979% | R: 0.8713%\n",
      "4_late: A: 0.7845% | P: 0.7793% | R: 0.8234%\n",
      "5_late: A: 0.7809% | P: 0.8049% | R: 0.7698%\n",
      "6_late: A: 0.7891% | P: 0.7780% | R: 0.8382%\n",
      "7_late: A: 0.7634% | P: 0.8176% | R: 0.7080%\n",
      "8_late: A: 0.7753% | P: 0.7963% | R: 0.7695%\n",
      "9_late: A: 0.7762% | P: 0.8019% | R: 0.7628%\n",
      "A_avg: 0.7671% | P_avg: 0.7793 | R_avg: 0.7829\n"
     ]
    }
   ],
   "source": [
    "a_total, p_total, r_total = 0,0,0\n",
    "for k,v in sorted(experiments.items()):\n",
    "    if k.endswith('_early'):\n",
    "        print('{:2}: A: {:.4f}% | P: {:.4f}% | R: {:.4f}%'.format(k, v['accuracy'], v['precision'], v['recall']))\n",
    "        a_total += v['accuracy']\n",
    "        p_total += v['precision']\n",
    "        r_total += v['recall']\n",
    "print('A_avg: {:.4f}% | P_avg: {:.4f} | R_avg: {:.4f}'.format(a_total/15, p_total/15, r_total/15))\n",
    " \n",
    "print()\n",
    "\n",
    "a_total, p_total, r_total = 0,0,0\n",
    "for k,v in sorted(experiments.items()):\n",
    "    if k.endswith('_late'):\n",
    "        print('{:2}: A: {:.4f}% | P: {:.4f}% | R: {:.4f}%'.format(k, v['accuracy'], v['precision'], v['recall']))\n",
    "        a_total += v['accuracy']\n",
    "        p_total += v['precision']\n",
    "        r_total += v['recall']\n",
    "print('A_avg: {:.4f}% | P_avg: {:.4f} | R_avg: {:.4f}'.format(a_total/15, p_total/15, r_total/15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history.items():\n",
    "    print('{:2}: A: {:.4f}% | P: {:.4f}% | R: {:.4f}%'.format(k, v['accuracy'], v['precision'], v['recall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: 0.8027    P: 0.8672    R: 0.7379\n",
    "# A: 0.7836    P: 0.8032    R: 0.7795\n",
    "# A: 0.8027    P: 0.8473    R: 0.7379"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
