{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from collections import Counter\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    CREATE AUGMENTER PIPELINE\n",
    "    wsi_dataset.py\n",
    "\"\"\"\n",
    "def get_seq():\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            iaa.Fliplr(0.5),  # horizontally flip 50% of all images\n",
    "            iaa.Flipud(0.2),  # vertically flip 20% of all images\n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                # scale images to 80-120% of their size, individually per axis\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},  # translate by -20 to +20 percent (per axis)\n",
    "                rotate=(-10, 10),  # rotate by -45 to +45 degrees\n",
    "                shear=(-5, 5),  # shear by -16 to +16 degrees\n",
    "                order=[0, 1],  # use nearest neighbour or bilinear interpolation (fast)\n",
    "                cval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n",
    "                mode=ia.ALL  # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            )),\n",
    "            # execute 0 to 5 of the following (less important) augmenters per image\n",
    "            # don't execute all of them, as that would often be way too strong\n",
    "            iaa.SomeOf((0, 5),\n",
    "                       [\n",
    "                           sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))),\n",
    "                           # convert images into their superpixel representation\n",
    "                           iaa.OneOf([\n",
    "                               iaa.GaussianBlur((0, 1.0)),  # blur images with a sigma between 0 and 3.0\n",
    "                               iaa.AverageBlur(k=(3, 5)),\n",
    "                               # blur image using local means with kernel sizes between 2 and 7\n",
    "                               iaa.MedianBlur(k=(3, 5)),\n",
    "                               # blur image using local medians with kernel sizes between 2 and 7\n",
    "                           ]),\n",
    "                           iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)),  # sharpen images\n",
    "                           iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),  # emboss images\n",
    "                           # search either for all edges or for directed edges,\n",
    "                           # blend the result with the original image using a blobby mask\n",
    "                           iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                               iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                               iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                           ])),\n",
    "                           iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01 * 255), per_channel=0.5),\n",
    "                           # add gaussian noise to images\n",
    "                           iaa.OneOf([\n",
    "                               iaa.Dropout((0.01, 0.05), per_channel=0.5),  # randomly remove up to 10% of the pixels\n",
    "                               iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
    "                           ]),\n",
    "                           iaa.Invert(0.01, per_channel=True),  # invert color channels\n",
    "                           iaa.Add((-2, 2), per_channel=0.5),\n",
    "                           # change brightness of images (by -10 to 10 of original value)\n",
    "                           iaa.AddToHueAndSaturation((-1, 1)),  # change hue and saturation\n",
    "                           # either change the brightness of the whole image (sometimes\n",
    "                           # per channel) or change the brightness of subareas\n",
    "                           iaa.OneOf([\n",
    "                               iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                               iaa.FrequencyNoiseAlpha(\n",
    "                                   exponent=(-1, 0),\n",
    "                                   first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
    "                                   second=iaa.ContrastNormalization((0.9, 1.1))\n",
    "                               )\n",
    "                           ]),\n",
    "                           sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)),\n",
    "                           # move pixels locally around (with random strengths)\n",
    "                           sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n",
    "                           # sometimes move parts of the image around\n",
    "                           sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                       ],\n",
    "                       random_order=True\n",
    "                       )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return seq\n",
    "seq = get_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 107712)       0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 107712)       0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    CREATE NASNET MODEL\n",
    "    nasnet_model.py\n",
    "\"\"\"\n",
    "def get_model_classif_nasnet():\n",
    "    inputs = Input((299, 299, 3))\n",
    "    base_model = NASNetMobile(include_top=False, input_tensor=inputs, weights='imagenet')\n",
    "    x = base_model(inputs)\n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizer=Adam(0.0001), loss=binary_crossentropy, metrics=['acc', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "model = get_model_classif_nasnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    WEIGHTED FILENAME SAMPLING\n",
    "    wsi_dataset.py\n",
    "\"\"\"\n",
    "DATASET_DIR_TRAIN = '/home/matejg/Project/crc_ml/data/processed/train_slides/'\n",
    "DATASET_DIR_VALID = '/home/matejg/Project/crc_ml/data/processed/valid_slides/'\n",
    "DATASET_DIR_TEST = '/home/matejg/Project/crc_ml/data/processed/test_slides/'\n",
    "\n",
    "def get_filenames(data_type='train'):\n",
    "    if data_type == 'train':\n",
    "        DATASET_DIR = DATASET_DIR_TRAIN\n",
    "    elif data_type == 'valid':\n",
    "        DATASET_DIR = DATASET_DIR_VALID\n",
    "    elif data_type == 'test':\n",
    "        DATASET_DIR = DATASET_DIR_TEST\n",
    "    \n",
    "    all_tiles = []\n",
    "    all_labels = []\n",
    "    all_weights = []\n",
    "\n",
    "    for label_id, label_name in {'0': 'normal', '1': 'cancer'}.items():\n",
    "\n",
    "        slides = glob.glob(DATASET_DIR + '/*/{}'.format(label_name))\n",
    "        print('Found {} {} slides.'.format(len(slides), label_name))\n",
    "        per_slide_proba = 0.5 / len(slides)\n",
    "        print('Each {} slide will be selected with proba {:.4f}'.format(label_name, per_slide_proba))\n",
    "\n",
    "        for slide in slides:\n",
    "            slide_tiles = glob.glob(slide + '/*w299-h299.png')\n",
    "            print('   - found {} tiles.'.format(len(slide_tiles)))\n",
    "            slide_labels = [label_id] * len(slide_tiles)\n",
    "            slide_weights = [per_slide_proba / len(slide_tiles)] * len(slide_tiles)\n",
    "\n",
    "            all_tiles += slide_tiles\n",
    "            all_labels += slide_labels\n",
    "            all_weights += slide_weights\n",
    "    pd_data = pd.DataFrame({'filename': all_tiles, 'class': all_labels})\n",
    "    return pd_data, all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    AUGMENTERS FOR TEST DATASET\n",
    "    wsi_dataset.py\n",
    "\"\"\"\n",
    "def get_test_augmenter(augment_type):\n",
    "    seq = None\n",
    "    if augment_type == 'h':\n",
    "        print('Horizontal augment.')\n",
    "        seq = iaa.Sequential([iaa.Fliplr(1)])\n",
    "    elif augment_type == 'v':\n",
    "        print('Vertical augment')\n",
    "        seq = iaa.Sequential([iaa.Flipud(1)])\n",
    "    elif augment_type == 'b':\n",
    "        print('Horizontal+Vertical augment')\n",
    "        seq = iaa.Sequential([iaa.Flipud(1), iaa.Fliplr(1)])\n",
    "    return seq\n",
    "\n",
    "\"\"\"\n",
    "    UTILITY CHUNKER\n",
    "    wsi_dataset.py\n",
    "\"\"\"\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    SHORTCUT UTILITY FUNCTION\n",
    "    wsi_dataset.py\n",
    "\"\"\"\n",
    "def divide_round_up(n, d):\n",
    "    return (n + (d - 1))//d\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    TEST DATA GENERATOR\n",
    "    wsi_dataset.py\n",
    "\"\"\"\n",
    "def test_data_gen(pd_data, batch_size, augment=None, shuffle=True):\n",
    "    if augment in ['h','v','b']:\n",
    "        seq = get_test_augmenter(augment)\n",
    "    else:\n",
    "        seq = get_seq()\n",
    "    \n",
    "    while True:\n",
    "        if shuffle:\n",
    "            pd_data = pd_data.sample(frac=1)\n",
    "            \n",
    "        for batch in chunker(pd_data, batch_size):\n",
    "            data = [cv2.imread(x) for x in batch['filename']]\n",
    "            if augment != 'n':\n",
    "                data = seq.augment_images(data)\n",
    "            data = [preprocess_input(x) for x in data]\n",
    "            yield np.array(data), np.array(batch['class'])\n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "    TRAIN DATA GENERATOR\n",
    "    wsi_dataset.py\n",
    "\"\"\"\n",
    "def data_gen(pd_data, weights, batch_size):\n",
    "    while True:\n",
    "        batch = pd_data.sample(n=batch_size, replace=True, weights=weights)\n",
    "        data = [cv2.imread(x) for x in batch['filename']]\n",
    "        data = seq.augment_images(data)\n",
    "        data = [preprocess_input(x) for x in data]\n",
    "        yield np.array(data), np.array(batch['class'].astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 cancer slides.\n",
      "Each cancer slide will be selected with proba 0.0455\n",
      "   - found 582 tiles.\n",
      "   - found 4815 tiles.\n",
      "   - found 618 tiles.\n",
      "   - found 1144 tiles.\n",
      "   - found 343 tiles.\n",
      "   - found 2823 tiles.\n",
      "   - found 626 tiles.\n",
      "   - found 2789 tiles.\n",
      "   - found 3283 tiles.\n",
      "   - found 621 tiles.\n",
      "   - found 567 tiles.\n",
      "Found 36 normal slides.\n",
      "Each normal slide will be selected with proba 0.0139\n",
      "   - found 3105 tiles.\n",
      "   - found 7526 tiles.\n",
      "   - found 3479 tiles.\n",
      "   - found 4450 tiles.\n",
      "   - found 5101 tiles.\n",
      "   - found 6929 tiles.\n",
      "   - found 5661 tiles.\n",
      "   - found 6291 tiles.\n",
      "   - found 10695 tiles.\n",
      "   - found 4887 tiles.\n",
      "   - found 3804 tiles.\n",
      "   - found 4823 tiles.\n",
      "   - found 21844 tiles.\n",
      "   - found 16419 tiles.\n",
      "   - found 3369 tiles.\n",
      "   - found 7216 tiles.\n",
      "   - found 6878 tiles.\n",
      "   - found 3903 tiles.\n",
      "   - found 45182 tiles.\n",
      "   - found 2950 tiles.\n",
      "   - found 4949 tiles.\n",
      "   - found 5501 tiles.\n",
      "   - found 4725 tiles.\n",
      "   - found 6974 tiles.\n",
      "   - found 18677 tiles.\n",
      "   - found 4447 tiles.\n",
      "   - found 3634 tiles.\n",
      "   - found 2308 tiles.\n",
      "   - found 4386 tiles.\n",
      "   - found 12760 tiles.\n",
      "   - found 6352 tiles.\n",
      "   - found 4813 tiles.\n",
      "   - found 5177 tiles.\n",
      "   - found 8223 tiles.\n",
      "   - found 6022 tiles.\n",
      "   - found 16993 tiles.\n",
      "Found 11 cancer slides.\n",
      "Each cancer slide will be selected with proba 0.0455\n",
      "   - found 65 tiles.\n",
      "   - found 535 tiles.\n",
      "   - found 69 tiles.\n",
      "   - found 128 tiles.\n",
      "   - found 39 tiles.\n",
      "   - found 314 tiles.\n",
      "   - found 70 tiles.\n",
      "   - found 310 tiles.\n",
      "   - found 366 tiles.\n",
      "   - found 69 tiles.\n",
      "   - found 64 tiles.\n",
      "Found 36 normal slides.\n",
      "Each normal slide will be selected with proba 0.0139\n",
      "   - found 345 tiles.\n",
      "   - found 836 tiles.\n",
      "   - found 387 tiles.\n",
      "   - found 496 tiles.\n",
      "   - found 567 tiles.\n",
      "   - found 771 tiles.\n",
      "   - found 630 tiles.\n",
      "   - found 700 tiles.\n",
      "   - found 1189 tiles.\n",
      "   - found 543 tiles.\n",
      "   - found 423 tiles.\n",
      "   - found 537 tiles.\n",
      "   - found 2428 tiles.\n",
      "   - found 1825 tiles.\n",
      "   - found 375 tiles.\n",
      "   - found 803 tiles.\n",
      "   - found 766 tiles.\n",
      "   - found 434 tiles.\n",
      "   - found 5022 tiles.\n",
      "   - found 328 tiles.\n",
      "   - found 550 tiles.\n",
      "   - found 612 tiles.\n",
      "   - found 526 tiles.\n",
      "   - found 775 tiles.\n",
      "   - found 2076 tiles.\n",
      "   - found 495 tiles.\n",
      "   - found 404 tiles.\n",
      "   - found 257 tiles.\n",
      "   - found 488 tiles.\n",
      "   - found 1418 tiles.\n",
      "   - found 706 tiles.\n",
      "   - found 537 tiles.\n",
      "   - found 576 tiles.\n",
      "   - found 914 tiles.\n",
      "   - found 670 tiles.\n",
      "   - found 1892 tiles.\n",
      "Found 2 cancer slides.\n",
      "Each cancer slide will be selected with proba 0.2500\n",
      "   - found 7145 tiles.\n",
      "   - found 1080 tiles.\n",
      "Found 2 normal slides.\n",
      "Each normal slide will be selected with proba 0.2500\n",
      "   - found 3600 tiles.\n",
      "   - found 4149 tiles.\n"
     ]
    }
   ],
   "source": [
    "train_fn, train_w = get_filenames('train')\n",
    "valid_fn, valid_w = get_filenames('valid')\n",
    "test_fn, test_w = get_filenames('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_fn = train_fn[train_fn['class'] == '0'].sample(n=len(train_fn[train_fn['class'] == '1']))\n",
    "new_train_fn = pd.concat([new_train_fn, train_fn[train_fn['class'] == '1']])\n",
    "new_train_fn = new_train_fn.sample(frac=1)\n",
    "\n",
    "new_valid_fn = valid_fn[valid_fn['class'] == '0'].sample(n=len(valid_fn[valid_fn['class'] == '1']))\n",
    "new_valid_fn = pd.concat([new_valid_fn, valid_fn[valid_fn['class'] == '1']])\n",
    "new_valid_fn = new_valid_fn.sample(frac=1)\n",
    "\n",
    "new_test_fn = test_fn[test_fn['class'] == '0'].sample(n=len(test_fn[test_fn['class'] == '1']))\n",
    "new_test_fn = pd.concat([new_test_fn, valid_fn[test_fn['class'] == '1']])\n",
    "new_test_fn = new_test_fn.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('/home/matejg/nasnet-wsi.h5', monitor='val_precision', verbose=1, save_best_only=True, mode='max', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.fit_generator(\n",
    "    test_data_gen(new_train_fn, batch_size),\n",
    "    validation_data=test_data_gen(valid_fn, batch_size, shuffle=False),\n",
    "    epochs=6, verbose=1,\n",
    "    callbacks=[checkpoint],\n",
    "    steps_per_epoch=divide_round_up(len(new_train_fn), batch_size),\n",
    "    validation_steps=divide_round_up(len(valid_fn), batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 95s 191ms/step\n",
      "Horizontal augment.\n",
      "500/500 [==============================] - 96s 192ms/step\n",
      "Vertical augment\n",
      "500/500 [==============================] - 89s 177ms/step\n",
      "Horizontal+Vertical augment\n",
      "500/500 [==============================] - 95s 189ms/step\n",
      "Acc: 0.710\tP: 0.674\tR: 0.845\n",
      "Acc: 0.722\tP: 0.695\tR: 0.820\n",
      "Acc: 0.716\tP: 0.684\tR: 0.832\n",
      "Acc: 0.721\tP: 0.693\tR: 0.822\n",
      "Acc: 0.727\tP: 0.699\tR: 0.825\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    used_ds = test_fn\n",
    "    #model.load_weights('/home/matejg/nasnet-wsi.h5')\n",
    "    experiment_id = 'f81c0d8e-03c2-40f9-89ee-15bedbd89a57'\n",
    "    model.load_weights('/home/matejg/Project/crc_ml/models/checkpoints/{eid}/{eid}.hdf5'.format(eid=experiment_id))\n",
    "\n",
    "    res_normal = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='n', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "\n",
    "    res_horizontal = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='h', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "\n",
    "    res_vertical = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='v', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "\n",
    "    res_both = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='b', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "    \n",
    "    res_combined = np.array((res_normal.ravel() * res_horizontal.ravel() * res_vertical.ravel() * res_both.ravel()) ** 0.25)\n",
    "    for res in [res_normal, res_vertical, res_horizontal, res_both, res_combined]:\n",
    "        acc = tf.keras.metrics.BinaryAccuracy()\n",
    "        acc.update_state(used_ds['class'].ravel().astype(np.float), res.ravel())\n",
    "\n",
    "        p = tf.keras.metrics.Precision()\n",
    "        p.update_state(used_ds['class'].ravel().astype(np.float), res.ravel())\n",
    "\n",
    "        r = tf.keras.metrics.Recall()\n",
    "        r.update_state(used_ds['class'].ravel().astype(np.float), res.ravel())\n",
    "        \n",
    "        print('Acc: {:.3f}\\tP: {:.3f}\\tR: {:.3f}'.format(acc.result().numpy(), p.result().numpy(), r.result().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for guess, truth in zip(res_combined, test_fn['class'].ravel()):\n",
    "    if ((guess < 0.5) and (truth == '1')) or (guess >= 0.5 and truth == '0'):\n",
    "        print('{:.5f}\\t{}'.format(guess, truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = {0: (0.91153276, 0.90771484, 0.9162149),\n",
    " 1: (0.92237556, 0.9302209, 0.9132578),\n",
    " 2: (0.9078364, 0.94133335, 0.86988664),\n",
    " 3: (0.90832925, 0.8795236, 0.9462789),\n",
    " 4: (0.92336124, 0.92609125, 0.92015773),\n",
    " 5: (0.9070971, 0.9171717, 0.89502215),\n",
    " 6: (0.9098078, 0.9138875, 0.9048793),\n",
    " 7: (0.9103006, 0.9258312, 0.89206505),\n",
    " 8: (0.9132578, 0.911231, 0.915722),\n",
    " 9: (0.91695416, 0.90988374, 0.92557913)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.91153276, 0.90771484, 0.9162149),\n",
       " 1: (0.92237556, 0.9302209, 0.9132578),\n",
       " 2: (0.9078364, 0.94133335, 0.86988664),\n",
       " 3: (0.90832925, 0.8795236, 0.9462789),\n",
       " 4: (0.92336124, 0.92609125, 0.92015773),\n",
       " 5: (0.9070971, 0.9171717, 0.89502215),\n",
       " 6: (0.9098078, 0.9138875, 0.9048793),\n",
       " 7: (0.9103006, 0.9258312, 0.89206505),\n",
       " 8: (0.9132578, 0.911231, 0.915722),\n",
       " 9: (0.91695416, 0.90988374, 0.92557913),\n",
       " 10: (0.9073435, 0.9017987, 0.91424346),\n",
       " 11: (0.90857565, 0.9400212, 0.87284374),\n",
       " 12: (0.8824544, 0.9394111, 0.8176442),\n",
       " 13: (0.91670775, 0.92253876, 0.9098078),\n",
       " 14: (0.915722, 0.89806515, 0.9379004),\n",
       " 15: (0.91670775, 0.9047391, 0.93149334),\n",
       " 16: (0.91202563, 0.94849783, 0.8713652),\n",
       " 17: (0.9159685, 0.90851885, 0.92508626),\n",
       " 18: (0.92286843, 0.9359756, 0.9078364),\n",
       " 19: (0.8925579, 0.9612044, 0.818137),\n",
       " 20: (0.90685064, 0.9244216, 0.88615084),\n",
       " 21: (0.9137506, 0.92985153, 0.89502215),\n",
       " 22: (0.919172, 0.9297625, 0.90685064),\n",
       " 23: (0.9107935, 0.91160494, 0.9098078),\n",
       " 24: (0.90832925, 0.9250898, 0.8886151),\n",
       " 25: (0.90660423, 0.88053507, 0.9408576),\n",
       " 26: (0.9248398, 0.9028037, 0.9521932),\n",
       " 27: (0.9098078, 0.9328475, 0.8831937),\n",
       " 28: (0.9125185, 0.90395755, 0.92311484),\n",
       " 29: (0.9046328, 0.93810034, 0.86643666)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 107712)       0           global_max_pooling2d[0][0]       \n",
      "                                                                 global_average_pooling2d[0][0]   \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 107712)       0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/matejg/Test/test/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "127/127 [==============================] - 71s 560ms/step - loss: 0.5145 - acc: 0.7802 - precision: 0.8529 - recall: 0.6772\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78019, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1115s 979ms/step - loss: 0.5042 - acc: 0.7668 - precision: 0.7716 - recall: 0.7581 - val_loss: 0.5145 - val_acc: 0.7802 - val_precision: 0.8529 - val_recall: 0.6772\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 71s 558ms/step - loss: 0.4371 - acc: 0.8100 - precision: 0.8619 - recall: 0.7383\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.78019 to 0.81000, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 995s 873ms/step - loss: 0.3601 - acc: 0.8376 - precision: 0.8478 - recall: 0.8229 - val_loss: 0.4371 - val_acc: 0.8100 - val_precision: 0.8619 - val_recall: 0.7383\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 68s 536ms/step - loss: 0.4053 - acc: 0.8443 - precision: 0.8020 - recall: 0.9142\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81000 to 0.84426, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 992s 871ms/step - loss: 0.3153 - acc: 0.8592 - precision: 0.8676 - recall: 0.8477 - val_loss: 0.4053 - val_acc: 0.8443 - val_precision: 0.8020 - val_recall: 0.9142\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 70s 552ms/step - loss: 0.3101 - acc: 0.8807 - precision: 0.8652 - recall: 0.9019\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84426 to 0.88073, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 996s 874ms/step - loss: 0.2908 - acc: 0.8727 - precision: 0.8774 - recall: 0.8665 - val_loss: 0.3101 - val_acc: 0.8807 - val_precision: 0.8652 - val_recall: 0.9019\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 72s 567ms/step - loss: 0.2996 - acc: 0.8758 - precision: 0.8565 - recall: 0.9029\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88073\n",
      "1139/1139 [==============================] - 996s 875ms/step - loss: 0.2702 - acc: 0.8857 - precision: 0.8924 - recall: 0.8771 - val_loss: 0.2996 - val_acc: 0.8758 - val_precision: 0.8565 - val_recall: 0.9029\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 70s 553ms/step - loss: 0.3242 - acc: 0.8682 - precision: 0.8359 - recall: 0.9162\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88073\n",
      "1139/1139 [==============================] - 997s 875ms/step - loss: 0.2567 - acc: 0.8910 - precision: 0.8988 - recall: 0.8812 - val_loss: 0.3242 - val_acc: 0.8682 - val_precision: 0.8359 - val_recall: 0.9162\n",
      "127/127 [==============================] - 26s 205ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 21s 168ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 20s 160ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 21s 169ms/step\n",
      "Acc: 0.902\tP: 0.888\tR: 0.920\n",
      "Acc: 0.906\tP: 0.897\tR: 0.918\n",
      "Acc: 0.902\tP: 0.892\tR: 0.916\n",
      "Acc: 0.904\tP: 0.894\tR: 0.916\n",
      "Acc: 0.907\tP: 0.902\tR: 0.914\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 107712)       0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 107712)       0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "127/127 [==============================] - 70s 552ms/step - loss: 0.5654 - acc: 0.7647 - precision_6: 0.8048 - recall_6: 0.6989\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76466, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1137s 998ms/step - loss: 0.4998 - acc: 0.7674 - precision_6: 0.7729 - recall_6: 0.7575 - val_loss: 0.5654 - val_acc: 0.7647 - val_precision_6: 0.8048 - val_recall_6: 0.6989\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 68s 534ms/step - loss: 0.5264 - acc: 0.7750 - precision_6: 0.8980 - recall_6: 0.6205\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76466 to 0.77501, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 986s 866ms/step - loss: 0.3600 - acc: 0.8372 - precision_6: 0.8468 - recall_6: 0.8233 - val_loss: 0.5264 - val_acc: 0.7750 - val_precision_6: 0.8980 - val_recall_6: 0.6205\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 68s 536ms/step - loss: 0.3082 - acc: 0.8608 - precision_6: 0.9004 - recall_6: 0.8112\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77501 to 0.86077, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 987s 867ms/step - loss: 0.3176 - acc: 0.8624 - precision_6: 0.8714 - recall_6: 0.8502 - val_loss: 0.3082 - val_acc: 0.8608 - val_precision_6: 0.9004 - val_recall_6: 0.8112\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 67s 530ms/step - loss: 0.3150 - acc: 0.8741 - precision_6: 0.8419 - recall_6: 0.9211\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86077 to 0.87408, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 988s 867ms/step - loss: 0.2921 - acc: 0.8754 - precision_6: 0.8828 - recall_6: 0.8656 - val_loss: 0.3150 - val_acc: 0.8741 - val_precision_6: 0.8419 - val_recall_6: 0.9211\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 71s 557ms/step - loss: 0.2820 - acc: 0.8825 - precision_6: 0.9222 - recall_6: 0.8354\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87408 to 0.88245, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 989s 868ms/step - loss: 0.2699 - acc: 0.8835 - precision_6: 0.8895 - recall_6: 0.8758 - val_loss: 0.2820 - val_acc: 0.8825 - val_precision_6: 0.9222 - val_recall_6: 0.8354\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 70s 552ms/step - loss: 0.3007 - acc: 0.8706 - precision_6: 0.8561 - recall_6: 0.8911\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88245\n",
      "1139/1139 [==============================] - 989s 869ms/step - loss: 0.2580 - acc: 0.8910 - precision_6: 0.8968 - recall_6: 0.8836 - val_loss: 0.3007 - val_acc: 0.8706 - val_precision_6: 0.8561 - val_recall_6: 0.8911\n",
      "127/127 [==============================] - 32s 255ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 22s 176ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 20s 158ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 21s 168ms/step\n",
      "Acc: 0.904\tP: 0.928\tR: 0.875\n",
      "Acc: 0.907\tP: 0.930\tR: 0.880\n",
      "Acc: 0.904\tP: 0.925\tR: 0.879\n",
      "Acc: 0.899\tP: 0.927\tR: 0.867\n",
      "Acc: 0.909\tP: 0.940\tR: 0.873\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 107712)       0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 107712)       0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 81s 639ms/step - loss: 0.5135 - acc: 0.7758 - precision_12: 0.8728 - recall_12: 0.6456\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77575, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1196s 1s/step - loss: 0.5026 - acc: 0.7707 - precision_12: 0.7765 - recall_12: 0.7603 - val_loss: 0.5135 - val_acc: 0.7758 - val_precision_12: 0.8728 - val_recall_12: 0.6456\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 67s 526ms/step - loss: 0.4370 - acc: 0.8103 - precision_12: 0.8855 - recall_12: 0.7127\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.77575 to 0.81025, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 996s 875ms/step - loss: 0.3584 - acc: 0.8374 - precision_12: 0.8495 - recall_12: 0.8200 - val_loss: 0.4370 - val_acc: 0.8103 - val_precision_12: 0.8855 - val_recall_12: 0.7127\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 71s 562ms/step - loss: 0.3765 - acc: 0.8376 - precision_12: 0.8760 - recall_12: 0.7866\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81025 to 0.83760, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1001s 879ms/step - loss: 0.3136 - acc: 0.8614 - precision_12: 0.8701 - recall_12: 0.8497 - val_loss: 0.3765 - val_acc: 0.8376 - val_precision_12: 0.8760 - val_recall_12: 0.7866\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 70s 551ms/step - loss: 0.5057 - acc: 0.8445 - precision_12: 0.7905 - recall_12: 0.9374\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.83760 to 0.84450, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 999s 877ms/step - loss: 0.2867 - acc: 0.8758 - precision_12: 0.8813 - recall_12: 0.8686 - val_loss: 0.5057 - val_acc: 0.8445 - val_precision_12: 0.7905 - val_recall_12: 0.9374\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 67s 530ms/step - loss: 0.3202 - acc: 0.8618 - precision_12: 0.9110 - recall_12: 0.8019\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.84450 to 0.86175, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 997s 875ms/step - loss: 0.2701 - acc: 0.8851 - precision_12: 0.8892 - recall_12: 0.8797 - val_loss: 0.3202 - val_acc: 0.8618 - val_precision_12: 0.9110 - val_recall_12: 0.8019\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 70s 548ms/step - loss: 0.4310 - acc: 0.8132 - precision_12: 0.9245 - recall_12: 0.6821\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.86175\n",
      "1139/1139 [==============================] - 999s 877ms/step - loss: 0.2575 - acc: 0.8914 - precision_12: 0.8977 - recall_12: 0.8836 - val_loss: 0.4310 - val_acc: 0.8132 - val_precision_12: 0.9245 - val_recall_12: 0.6821\n",
      "127/127 [==============================] - 41s 319ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 21s 169ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 20s 160ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 22s 174ms/step\n",
      "Acc: 0.883\tP: 0.932\tR: 0.827\n",
      "Acc: 0.883\tP: 0.935\tR: 0.823\n",
      "Acc: 0.887\tP: 0.932\tR: 0.835\n",
      "Acc: 0.874\tP: 0.933\tR: 0.806\n",
      "Acc: 0.882\tP: 0.939\tR: 0.818\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 107712)       0           global_max_pooling2d_3[0][0]     \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 107712)       0           concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 86s 675ms/step - loss: 0.5008 - acc: 0.7876 - precision_18: 0.8733 - recall_18: 0.6727\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78758, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1234s 1s/step - loss: 0.4953 - acc: 0.7716 - precision_18: 0.7781 - recall_18: 0.7599 - val_loss: 0.5008 - val_acc: 0.7876 - val_precision_18: 0.8733 - val_recall_18: 0.6727\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 70s 554ms/step - loss: 0.3328 - acc: 0.8536 - precision_18: 0.8666 - recall_18: 0.8359\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.78758 to 0.85362, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 997s 875ms/step - loss: 0.3517 - acc: 0.8427 - precision_18: 0.8528 - recall_18: 0.8284 - val_loss: 0.3328 - val_acc: 0.8536 - val_precision_18: 0.8666 - val_recall_18: 0.8359\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 70s 548ms/step - loss: 0.3429 - acc: 0.8605 - precision_18: 0.9280 - recall_18: 0.7817\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85362 to 0.86052, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 997s 875ms/step - loss: 0.3138 - acc: 0.8632 - precision_18: 0.8713 - recall_18: 0.8523 - val_loss: 0.3429 - val_acc: 0.8605 - val_precision_18: 0.9280 - val_recall_18: 0.7817\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 69s 542ms/step - loss: 0.3234 - acc: 0.8657 - precision_18: 0.8240 - recall_18: 0.9300\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86052 to 0.86570, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 997s 875ms/step - loss: 0.2858 - acc: 0.8769 - precision_18: 0.8848 - recall_18: 0.8667 - val_loss: 0.3234 - val_acc: 0.8657 - val_precision_18: 0.8240 - val_recall_18: 0.9300\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 69s 545ms/step - loss: 0.2665 - acc: 0.8866 - precision_18: 0.8799 - recall_18: 0.8955\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86570 to 0.88664, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 996s 874ms/step - loss: 0.2648 - acc: 0.8872 - precision_18: 0.8937 - recall_18: 0.8789 - val_loss: 0.2665 - val_acc: 0.8866 - val_precision_18: 0.8799 - val_recall_18: 0.8955\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 67s 531ms/step - loss: 0.2570 - acc: 0.8864 - precision_18: 0.9153 - recall_18: 0.8517\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88664\n",
      "1139/1139 [==============================] - 994s 873ms/step - loss: 0.2489 - acc: 0.8950 - precision_18: 0.8991 - recall_18: 0.8898 - val_loss: 0.2570 - val_acc: 0.8864 - val_precision_18: 0.9153 - val_recall_18: 0.8517\n",
      "127/127 [==============================] - 49s 384ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 22s 174ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 21s 165ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 22s 175ms/step\n",
      "Acc: 0.918\tP: 0.922\tR: 0.914\n",
      "Acc: 0.908\tP: 0.906\tR: 0.910\n",
      "Acc: 0.909\tP: 0.908\tR: 0.910\n",
      "Acc: 0.913\tP: 0.914\tR: 0.910\n",
      "Acc: 0.917\tP: 0.923\tR: 0.910\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 107712)       0           global_max_pooling2d_4[0][0]     \n",
      "                                                                 global_average_pooling2d_4[0][0] \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 107712)       0           concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 90s 712ms/step - loss: 0.8850 - acc: 0.6865 - precision_24: 0.6190 - recall_24: 0.9704\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68655, saving model to /home/matejg/nasnet-wsi.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1289s 1s/step - loss: 0.4997 - acc: 0.7704 - precision_24: 0.7786 - recall_24: 0.7558 - val_loss: 0.8850 - val_acc: 0.6865 - val_precision_24: 0.6190 - val_recall_24: 0.9704\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 68s 535ms/step - loss: 0.4590 - acc: 0.8172 - precision_24: 0.8960 - recall_24: 0.7176\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68655 to 0.81715, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1000s 878ms/step - loss: 0.3641 - acc: 0.8356 - precision_24: 0.8462 - recall_24: 0.8202 - val_loss: 0.4590 - val_acc: 0.8172 - val_precision_24: 0.8960 - val_recall_24: 0.7176\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 70s 552ms/step - loss: 0.3146 - acc: 0.8620 - precision_24: 0.8380 - recall_24: 0.8975\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81715 to 0.86200, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1002s 879ms/step - loss: 0.3196 - acc: 0.8585 - precision_24: 0.8675 - recall_24: 0.8463 - val_loss: 0.3146 - val_acc: 0.8620 - val_precision_24: 0.8380 - val_recall_24: 0.8975\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 72s 570ms/step - loss: 0.3436 - acc: 0.8581 - precision_24: 0.8122 - recall_24: 0.9315\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.86200\n",
      "1139/1139 [==============================] - 1004s 881ms/step - loss: 0.2966 - acc: 0.8711 - precision_24: 0.8783 - recall_24: 0.8617 - val_loss: 0.3436 - val_acc: 0.8581 - val_precision_24: 0.8122 - val_recall_24: 0.9315\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 71s 562ms/step - loss: 0.3081 - acc: 0.8691 - precision_24: 0.8353 - recall_24: 0.9197\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86200 to 0.86915, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1003s 880ms/step - loss: 0.2698 - acc: 0.8841 - precision_24: 0.8910 - recall_24: 0.8752 - val_loss: 0.3081 - val_acc: 0.8691 - val_precision_24: 0.8353 - val_recall_24: 0.9197\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 68s 539ms/step - loss: 0.2875 - acc: 0.8795 - precision_24: 0.8526 - recall_24: 0.9177\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.86915 to 0.87950, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1000s 878ms/step - loss: 0.2587 - acc: 0.8900 - precision_24: 0.8974 - recall_24: 0.8806 - val_loss: 0.2875 - val_acc: 0.8795 - val_precision_24: 0.8526 - val_recall_24: 0.9177\n",
      "127/127 [==============================] - 58s 459ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 22s 175ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 21s 162ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 22s 176ms/step\n",
      "Acc: 0.908\tP: 0.883\tR: 0.940\n",
      "Acc: 0.910\tP: 0.895\tR: 0.929\n",
      "Acc: 0.910\tP: 0.883\tR: 0.944\n",
      "Acc: 0.909\tP: 0.890\tR: 0.933\n",
      "Acc: 0.916\tP: 0.898\tR: 0.938\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_5 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 107712)       0           global_max_pooling2d_5[0][0]     \n",
      "                                                                 global_average_pooling2d_5[0][0] \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 107712)       0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 97s 760ms/step - loss: 0.5918 - acc: 0.7689 - precision_30: 0.7105 - recall_30: 0.9073\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76885, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1336s 1s/step - loss: 0.5032 - acc: 0.7689 - precision_30: 0.7743 - recall_30: 0.7592 - val_loss: 0.5918 - val_acc: 0.7689 - val_precision_30: 0.7105 - val_recall_30: 0.9073\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 70s 549ms/step - loss: 0.3387 - acc: 0.8514 - precision_30: 0.8512 - recall_30: 0.8517\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76885 to 0.85140, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1002s 880ms/step - loss: 0.3703 - acc: 0.8341 - precision_30: 0.8478 - recall_30: 0.8146 - val_loss: 0.3387 - val_acc: 0.8514 - val_precision_30: 0.8512 - val_recall_30: 0.8517\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 70s 553ms/step - loss: 0.3414 - acc: 0.8517 - precision_30: 0.8838 - recall_30: 0.8098\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85140 to 0.85165, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1005s 882ms/step - loss: 0.3255 - acc: 0.8564 - precision_30: 0.8666 - recall_30: 0.8425 - val_loss: 0.3414 - val_acc: 0.8517 - val_precision_30: 0.8838 - val_recall_30: 0.8098\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 68s 536ms/step - loss: 0.3085 - acc: 0.8701 - precision_30: 0.8632 - recall_30: 0.8797\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85165 to 0.87013, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1005s 882ms/step - loss: 0.2955 - acc: 0.8736 - precision_30: 0.8839 - recall_30: 0.8602 - val_loss: 0.3085 - val_acc: 0.8701 - val_precision_30: 0.8632 - val_recall_30: 0.8797\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 70s 553ms/step - loss: 0.2716 - acc: 0.8810 - precision_30: 0.8585 - recall_30: 0.9123\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87013 to 0.88098, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1003s 881ms/step - loss: 0.2752 - acc: 0.8804 - precision_30: 0.8877 - recall_30: 0.8710 - val_loss: 0.2716 - val_acc: 0.8810 - val_precision_30: 0.8585 - val_recall_30: 0.9123\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 72s 564ms/step - loss: 0.2962 - acc: 0.8731 - precision_30: 0.9287 - recall_30: 0.8083\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88098\n",
      "1139/1139 [==============================] - 997s 875ms/step - loss: 0.2569 - acc: 0.8901 - precision_30: 0.8969 - recall_30: 0.8816 - val_loss: 0.2962 - val_acc: 0.8731 - val_precision_30: 0.9287 - val_recall_30: 0.8083\n",
      "127/127 [==============================] - 69s 547ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 22s 174ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 21s 165ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 22s 175ms/step\n",
      "Acc: 0.914\tP: 0.903\tR: 0.927\n",
      "Acc: 0.913\tP: 0.895\tR: 0.936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.915\tP: 0.899\tR: 0.934\n",
      "Acc: 0.910\tP: 0.893\tR: 0.931\n",
      "Acc: 0.917\tP: 0.905\tR: 0.931\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_6 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 107712)       0           global_max_pooling2d_6[0][0]     \n",
      "                                                                 global_average_pooling2d_6[0][0] \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 107712)       0           concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 108s 848ms/step - loss: 0.4671 - acc: 0.7965 - precision_36: 0.8503 - recall_36: 0.7196\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79645, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1392s 1s/step - loss: 0.5071 - acc: 0.7694 - precision_36: 0.7758 - recall_36: 0.7577 - val_loss: 0.4671 - val_acc: 0.7965 - val_precision_36: 0.8503 - val_recall_36: 0.7196\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 72s 565ms/step - loss: 0.3466 - acc: 0.8539 - precision_36: 0.9066 - recall_36: 0.7891\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79645 to 0.85387, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1013s 890ms/step - loss: 0.3610 - acc: 0.8389 - precision_36: 0.8502 - recall_36: 0.8229 - val_loss: 0.3466 - val_acc: 0.8539 - val_precision_36: 0.9066 - val_recall_36: 0.7891\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 71s 559ms/step - loss: 0.3336 - acc: 0.8674 - precision_36: 0.8396 - recall_36: 0.9083\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85387 to 0.86742, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1023s 898ms/step - loss: 0.3155 - acc: 0.8599 - precision_36: 0.8697 - recall_36: 0.8466 - val_loss: 0.3336 - val_acc: 0.8674 - val_precision_36: 0.8396 - val_recall_36: 0.9083\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 72s 564ms/step - loss: 0.3682 - acc: 0.8524 - precision_36: 0.9211 - recall_36: 0.7708\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.86742\n",
      "1139/1139 [==============================] - 1017s 893ms/step - loss: 0.2875 - acc: 0.8758 - precision_36: 0.8844 - recall_36: 0.8645 - val_loss: 0.3682 - val_acc: 0.8524 - val_precision_36: 0.9211 - val_recall_36: 0.7708\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 71s 556ms/step - loss: 0.3997 - acc: 0.8403 - precision_36: 0.9594 - recall_36: 0.7107\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.86742\n",
      "1139/1139 [==============================] - 1017s 893ms/step - loss: 0.2699 - acc: 0.8853 - precision_36: 0.8930 - recall_36: 0.8755 - val_loss: 0.3997 - val_acc: 0.8403 - val_precision_36: 0.9594 - val_recall_36: 0.7107\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 72s 570ms/step - loss: 0.2769 - acc: 0.8931 - precision_36: 0.9126 - recall_36: 0.8694\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.86742 to 0.89305, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1019s 895ms/step - loss: 0.2530 - acc: 0.8926 - precision_36: 0.8995 - recall_36: 0.8840 - val_loss: 0.2769 - val_acc: 0.8931 - val_precision_36: 0.9126 - val_recall_36: 0.8694\n",
      "127/127 [==============================] - 82s 644ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 23s 179ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 22s 171ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 22s 173ms/step\n",
      "Acc: 0.908\tP: 0.937\tR: 0.875\n",
      "Acc: 0.907\tP: 0.934\tR: 0.876\n",
      "Acc: 0.909\tP: 0.939\tR: 0.874\n",
      "Acc: 0.905\tP: 0.933\tR: 0.873\n",
      "Acc: 0.912\tP: 0.948\tR: 0.871\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_7 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 107712)       0           global_max_pooling2d_7[0][0]     \n",
      "                                                                 global_average_pooling2d_7[0][0] \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 107712)       0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 118s 930ms/step - loss: 0.6254 - acc: 0.7701 - precision_42: 0.8865 - recall_42: 0.6195\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77008, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1447s 1s/step - loss: 0.5028 - acc: 0.7717 - precision_42: 0.7778 - recall_42: 0.7607 - val_loss: 0.6254 - val_acc: 0.7701 - val_precision_42: 0.8865 - val_recall_42: 0.6195\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 70s 549ms/step - loss: 0.4337 - acc: 0.8388 - precision_42: 0.8477 - recall_42: 0.8260\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.77008 to 0.83884, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1008s 885ms/step - loss: 0.3592 - acc: 0.8401 - precision_42: 0.8532 - recall_42: 0.8215 - val_loss: 0.4337 - val_acc: 0.8388 - val_precision_42: 0.8477 - val_recall_42: 0.8260\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 67s 531ms/step - loss: 0.4073 - acc: 0.8418 - precision_42: 0.8551 - recall_42: 0.8231\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83884 to 0.84179, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1009s 886ms/step - loss: 0.3179 - acc: 0.8601 - precision_42: 0.8713 - recall_42: 0.8450 - val_loss: 0.4073 - val_acc: 0.8418 - val_precision_42: 0.8551 - val_recall_42: 0.8231\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 83s 656ms/step - loss: 0.3206 - acc: 0.8694 - precision_42: 0.8683 - recall_42: 0.8709\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84179 to 0.86939, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1027s 901ms/step - loss: 0.2887 - acc: 0.8751 - precision_42: 0.8848 - recall_42: 0.8625 - val_loss: 0.3206 - val_acc: 0.8694 - val_precision_42: 0.8683 - val_recall_42: 0.8709\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 71s 560ms/step - loss: 0.2929 - acc: 0.8793 - precision_42: 0.8763 - recall_42: 0.8832\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86939 to 0.87925, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1022s 897ms/step - loss: 0.2689 - acc: 0.8833 - precision_42: 0.8917 - recall_42: 0.8727 - val_loss: 0.2929 - val_acc: 0.8793 - val_precision_42: 0.8763 - val_recall_42: 0.8832\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 73s 574ms/step - loss: 0.2995 - acc: 0.8839 - precision_42: 0.8647 - recall_42: 0.9103\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87925 to 0.88393, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1024s 899ms/step - loss: 0.2555 - acc: 0.8932 - precision_42: 0.8998 - recall_42: 0.8849 - val_loss: 0.2995 - val_acc: 0.8839 - val_precision_42: 0.8647 - val_recall_42: 0.9103\n",
      "127/127 [==============================] - 94s 744ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 23s 183ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 21s 169ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 23s 181ms/step\n",
      "Acc: 0.915\tP: 0.899\tR: 0.934\n",
      "Acc: 0.913\tP: 0.911\tR: 0.916\n",
      "Acc: 0.911\tP: 0.895\tR: 0.930\n",
      "Acc: 0.913\tP: 0.903\tR: 0.924\n",
      "Acc: 0.916\tP: 0.909\tR: 0.925\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_8 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 107712)       0           global_max_pooling2d_8[0][0]     \n",
      "                                                                 global_average_pooling2d_8[0][0] \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 107712)       0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 126s 990ms/step - loss: 0.7084 - acc: 0.7242 - precision_48: 0.8798 - recall_48: 0.5195\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72425, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1501s 1s/step - loss: 0.5073 - acc: 0.7667 - precision_48: 0.7723 - recall_48: 0.7564 - val_loss: 0.7084 - val_acc: 0.7242 - val_precision_48: 0.8798 - val_recall_48: 0.5195\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 68s 538ms/step - loss: 0.3942 - acc: 0.8379 - precision_48: 0.8453 - recall_48: 0.8270\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.72425 to 0.83785, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1015s 891ms/step - loss: 0.3628 - acc: 0.8364 - precision_48: 0.8479 - recall_48: 0.8199 - val_loss: 0.3942 - val_acc: 0.8379 - val_precision_48: 0.8453 - val_recall_48: 0.8270\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 71s 559ms/step - loss: 0.3256 - acc: 0.8608 - precision_48: 0.8355 - recall_48: 0.8985\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83785 to 0.86077, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1020s 896ms/step - loss: 0.3183 - acc: 0.8581 - precision_48: 0.8688 - recall_48: 0.8436 - val_loss: 0.3256 - val_acc: 0.8608 - val_precision_48: 0.8355 - val_recall_48: 0.8985\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 574ms/step - loss: 0.4958 - acc: 0.8295 - precision_48: 0.7600 - recall_48: 0.9630\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.86077\n",
      "1139/1139 [==============================] - 1021s 896ms/step - loss: 0.2914 - acc: 0.8747 - precision_48: 0.8834 - recall_48: 0.8634 - val_loss: 0.4958 - val_acc: 0.8295 - val_precision_48: 0.7600 - val_recall_48: 0.9630\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 73s 574ms/step - loss: 0.2797 - acc: 0.8874 - precision_48: 0.8793 - recall_48: 0.8980\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86077 to 0.88738, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1021s 896ms/step - loss: 0.2711 - acc: 0.8833 - precision_48: 0.8896 - recall_48: 0.8752 - val_loss: 0.2797 - val_acc: 0.8874 - val_precision_48: 0.8793 - val_recall_48: 0.8980\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 71s 562ms/step - loss: 0.2701 - acc: 0.8913 - precision_48: 0.8854 - recall_48: 0.8990\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.88738 to 0.89133, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1019s 894ms/step - loss: 0.2571 - acc: 0.8904 - precision_48: 0.8973 - recall_48: 0.8818 - val_loss: 0.2701 - val_acc: 0.8913 - val_precision_48: 0.8854 - val_recall_48: 0.8990\n",
      "127/127 [==============================] - 105s 828ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 24s 192ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 22s 173ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 24s 186ms/step\n",
      "Acc: 0.915\tP: 0.924\tR: 0.905\n",
      "Acc: 0.917\tP: 0.925\tR: 0.908\n",
      "Acc: 0.915\tP: 0.921\tR: 0.908\n",
      "Acc: 0.917\tP: 0.928\tR: 0.903\n",
      "Acc: 0.923\tP: 0.936\tR: 0.908\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_9 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 107712)       0           global_max_pooling2d_9[0][0]     \n",
      "                                                                 global_average_pooling2d_9[0][0] \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 107712)       0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "127/127 [==============================] - 143s 1s/step - loss: 0.4640 - acc: 0.7898 - precision_54: 0.8879 - recall_54: 0.6634\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78980, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1572s 1s/step - loss: 0.5053 - acc: 0.7692 - precision_54: 0.7743 - recall_54: 0.7598 - val_loss: 0.4640 - val_acc: 0.7898 - val_precision_54: 0.8879 - val_recall_54: 0.6634\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 73s 574ms/step - loss: 0.3427 - acc: 0.8526 - precision_54: 0.8682 - recall_54: 0.8314\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.78980 to 0.85264, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1025s 900ms/step - loss: 0.3585 - acc: 0.8369 - precision_54: 0.8476 - recall_54: 0.8215 - val_loss: 0.3427 - val_acc: 0.8526 - val_precision_54: 0.8682 - val_recall_54: 0.8314\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 71s 557ms/step - loss: 0.3098 - acc: 0.8696 - precision_54: 0.9223 - recall_54: 0.8073\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85264 to 0.86964, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1021s 897ms/step - loss: 0.3123 - acc: 0.8615 - precision_54: 0.8718 - recall_54: 0.8477 - val_loss: 0.3098 - val_acc: 0.8696 - val_precision_54: 0.9223 - val_recall_54: 0.8073\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 72s 564ms/step - loss: 0.3026 - acc: 0.8780 - precision_54: 0.9319 - recall_54: 0.8157\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86964 to 0.87802, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1025s 900ms/step - loss: 0.2912 - acc: 0.8747 - precision_54: 0.8834 - recall_54: 0.8633 - val_loss: 0.3026 - val_acc: 0.8780 - val_precision_54: 0.9319 - val_recall_54: 0.8157\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 70s 551ms/step - loss: 0.3665 - acc: 0.8716 - precision_54: 0.8179 - recall_54: 0.9561\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87802\n",
      "1139/1139 [==============================] - 1021s 897ms/step - loss: 0.2659 - acc: 0.8874 - precision_54: 0.8950 - recall_54: 0.8778 - val_loss: 0.3665 - val_acc: 0.8716 - val_precision_54: 0.8179 - val_recall_54: 0.9561\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 73s 577ms/step - loss: 0.3170 - acc: 0.8696 - precision_54: 0.8258 - recall_54: 0.9369\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87802\n",
      "1139/1139 [==============================] - 1025s 900ms/step - loss: 0.2524 - acc: 0.8928 - precision_54: 0.9001 - recall_54: 0.8838 - val_loss: 0.3170 - val_acc: 0.8696 - val_precision_54: 0.8258 - val_recall_54: 0.9369\n",
      "127/127 [==============================] - 119s 939ms/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 25s 194ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 23s 177ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 24s 188ms/step\n",
      "Acc: 0.894\tP: 0.952\tR: 0.830\n",
      "Acc: 0.890\tP: 0.955\tR: 0.819\n",
      "Acc: 0.893\tP: 0.953\tR: 0.826\n",
      "Acc: 0.890\tP: 0.956\tR: 0.819\n",
      "Acc: 0.893\tP: 0.961\tR: 0.818\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_10 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 107712)       0           global_max_pooling2d_10[0][0]    \n",
      "                                                                 global_average_pooling2d_10[0][0]\n",
      "                                                                 flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 107712)       0           concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 149s 1s/step - loss: 0.4731 - acc: 0.7666 - precision_60: 0.8522 - recall_60: 0.6451\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76663, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1649s 1s/step - loss: 0.5040 - acc: 0.7709 - precision_60: 0.7767 - recall_60: 0.7605 - val_loss: 0.4731 - val_acc: 0.7666 - val_precision_60: 0.8522 - val_recall_60: 0.6451\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 73s 573ms/step - loss: 0.3838 - acc: 0.8297 - precision_60: 0.8963 - recall_60: 0.7457\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76663 to 0.82972, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1029s 904ms/step - loss: 0.3526 - acc: 0.8393 - precision_60: 0.8497 - recall_60: 0.8243 - val_loss: 0.3838 - val_acc: 0.8297 - val_precision_60: 0.8963 - val_recall_60: 0.7457\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 71s 562ms/step - loss: 0.3141 - acc: 0.8620 - precision_60: 0.9033 - recall_60: 0.8107\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.82972 to 0.86200, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1028s 902ms/step - loss: 0.3135 - acc: 0.8610 - precision_60: 0.8689 - recall_60: 0.8504 - val_loss: 0.3141 - val_acc: 0.8620 - val_precision_60: 0.9033 - val_recall_60: 0.8107\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 576ms/step - loss: 0.3091 - acc: 0.8657 - precision_60: 0.8292 - recall_60: 0.9211\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86200 to 0.86570, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1031s 905ms/step - loss: 0.2884 - acc: 0.8761 - precision_60: 0.8829 - recall_60: 0.8671 - val_loss: 0.3091 - val_acc: 0.8657 - val_precision_60: 0.8292 - val_recall_60: 0.9211\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 71s 555ms/step - loss: 0.2767 - acc: 0.8778 - precision_60: 0.8730 - recall_60: 0.8842\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86570 to 0.87777, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1027s 901ms/step - loss: 0.2659 - acc: 0.8855 - precision_60: 0.8940 - recall_60: 0.8747 - val_loss: 0.2767 - val_acc: 0.8778 - val_precision_60: 0.8730 - val_recall_60: 0.8842\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 73s 572ms/step - loss: 0.2826 - acc: 0.8788 - precision_60: 0.9005 - recall_60: 0.8517\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87777 to 0.87876, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1029s 903ms/step - loss: 0.2510 - acc: 0.8954 - precision_60: 0.9005 - recall_60: 0.8891 - val_loss: 0.2826 - val_acc: 0.8788 - val_precision_60: 0.9005 - val_recall_60: 0.8517\n",
      "127/127 [==============================] - 133s 1s/step\n",
      "Horizontal augment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 25s 194ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 24s 187ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 25s 194ms/step\n",
      "Acc: 0.905\tP: 0.916\tR: 0.891\n",
      "Acc: 0.898\tP: 0.910\tR: 0.884\n",
      "Acc: 0.901\tP: 0.910\tR: 0.890\n",
      "Acc: 0.908\tP: 0.924\tR: 0.889\n",
      "Acc: 0.907\tP: 0.924\tR: 0.886\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_11 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 107712)       0           global_max_pooling2d_11[0][0]    \n",
      "                                                                 global_average_pooling2d_11[0][0]\n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 107712)       0           concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 167s 1s/step - loss: 0.4779 - acc: 0.7891 - precision_66: 0.8377 - recall_66: 0.7171\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78906, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1710s 2s/step - loss: 0.5001 - acc: 0.7707 - precision_66: 0.7767 - recall_66: 0.7599 - val_loss: 0.4779 - val_acc: 0.7891 - val_precision_66: 0.8377 - val_recall_66: 0.7171\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 71s 558ms/step - loss: 0.3499 - acc: 0.8391 - precision_66: 0.8468 - recall_66: 0.8280\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.78906 to 0.83908, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1024s 899ms/step - loss: 0.3631 - acc: 0.8373 - precision_66: 0.8464 - recall_66: 0.8242 - val_loss: 0.3499 - val_acc: 0.8391 - val_precision_66: 0.8468 - val_recall_66: 0.8280\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 71s 560ms/step - loss: 0.3546 - acc: 0.8346 - precision_66: 0.9450 - recall_66: 0.7107\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.83908\n",
      "1139/1139 [==============================] - 1023s 898ms/step - loss: 0.3223 - acc: 0.8561 - precision_66: 0.8634 - recall_66: 0.8461 - val_loss: 0.3546 - val_acc: 0.8346 - val_precision_66: 0.9450 - val_recall_66: 0.7107\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 71s 561ms/step - loss: 0.2899 - acc: 0.8810 - precision_66: 0.8724 - recall_66: 0.8926\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.83908 to 0.88098, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1025s 900ms/step - loss: 0.2924 - acc: 0.8733 - precision_66: 0.8796 - recall_66: 0.8649 - val_loss: 0.2899 - val_acc: 0.8810 - val_precision_66: 0.8724 - val_recall_66: 0.8926\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 71s 560ms/step - loss: 0.2922 - acc: 0.8763 - precision_66: 0.8530 - recall_66: 0.9093\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88098\n",
      "1139/1139 [==============================] - 1022s 897ms/step - loss: 0.2740 - acc: 0.8815 - precision_66: 0.8863 - recall_66: 0.8754 - val_loss: 0.2922 - val_acc: 0.8763 - val_precision_66: 0.8530 - val_recall_66: 0.9093\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 73s 573ms/step - loss: 0.2747 - acc: 0.8866 - precision_66: 0.8936 - recall_66: 0.8778\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.88098 to 0.88664, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1025s 900ms/step - loss: 0.2583 - acc: 0.8912 - precision_66: 0.8958 - recall_66: 0.8854 - val_loss: 0.2747 - val_acc: 0.8866 - val_precision_66: 0.8936 - val_recall_66: 0.8778\n",
      "127/127 [==============================] - 150s 1s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 24s 193ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 23s 177ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 24s 190ms/step\n",
      "Acc: 0.912\tP: 0.924\tR: 0.897\n",
      "Acc: 0.908\tP: 0.920\tR: 0.894\n",
      "Acc: 0.911\tP: 0.927\tR: 0.892\n",
      "Acc: 0.913\tP: 0.930\tR: 0.894\n",
      "Acc: 0.914\tP: 0.930\tR: 0.895\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_12 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 107712)       0           global_max_pooling2d_12[0][0]    \n",
      "                                                                 global_average_pooling2d_12[0][0]\n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 107712)       0           concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 182s 1s/step - loss: 0.6384 - acc: 0.7201 - precision_72: 0.8530 - recall_72: 0.5318\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72006, saving model to /home/matejg/nasnet-wsi.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1876s 2s/step - loss: 0.5096 - acc: 0.7689 - precision_72: 0.7740 - recall_72: 0.7595 - val_loss: 0.6384 - val_acc: 0.7201 - val_precision_72: 0.8530 - val_recall_72: 0.5318\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 70s 554ms/step - loss: 0.3765 - acc: 0.8305 - precision_72: 0.8328 - recall_72: 0.8270\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.72006 to 0.83046, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1041s 914ms/step - loss: 0.3629 - acc: 0.8380 - precision_72: 0.8478 - recall_72: 0.8240 - val_loss: 0.3765 - val_acc: 0.8305 - val_precision_72: 0.8328 - val_recall_72: 0.8270\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 72s 569ms/step - loss: 0.3341 - acc: 0.8610 - precision_72: 0.8547 - recall_72: 0.8699\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83046 to 0.86102, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1044s 916ms/step - loss: 0.3181 - acc: 0.8593 - precision_72: 0.8673 - recall_72: 0.8483 - val_loss: 0.3341 - val_acc: 0.8610 - val_precision_72: 0.8547 - val_recall_72: 0.8699\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 571ms/step - loss: 0.2910 - acc: 0.8778 - precision_72: 0.8673 - recall_72: 0.8921\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86102 to 0.87777, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1045s 918ms/step - loss: 0.2925 - acc: 0.8724 - precision_72: 0.8784 - recall_72: 0.8644 - val_loss: 0.2910 - val_acc: 0.8778 - val_precision_72: 0.8673 - val_recall_72: 0.8921\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 70s 552ms/step - loss: 0.4352 - acc: 0.8396 - precision_72: 0.7812 - recall_72: 0.9433\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87777\n",
      "1139/1139 [==============================] - 1041s 914ms/step - loss: 0.2717 - acc: 0.8824 - precision_72: 0.8863 - recall_72: 0.8775 - val_loss: 0.4352 - val_acc: 0.8396 - val_precision_72: 0.7812 - val_recall_72: 0.9433\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 73s 574ms/step - loss: 0.3427 - acc: 0.8773 - precision_72: 0.8336 - recall_72: 0.9428\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87777\n",
      "1139/1139 [==============================] - 1044s 917ms/step - loss: 0.2528 - acc: 0.8933 - precision_72: 0.9010 - recall_72: 0.8836 - val_loss: 0.3427 - val_acc: 0.8773 - val_precision_72: 0.8336 - val_recall_72: 0.9428\n",
      "127/127 [==============================] - 170s 1s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 25s 200ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 23s 181ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 25s 194ms/step\n",
      "Acc: 0.912\tP: 0.921\tR: 0.900\n",
      "Acc: 0.911\tP: 0.913\tR: 0.907\n",
      "Acc: 0.912\tP: 0.921\tR: 0.902\n",
      "Acc: 0.912\tP: 0.921\tR: 0.902\n",
      "Acc: 0.919\tP: 0.930\tR: 0.907\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_13 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 107712)       0           global_max_pooling2d_13[0][0]    \n",
      "                                                                 global_average_pooling2d_13[0][0]\n",
      "                                                                 flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 107712)       0           concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 197s 2s/step - loss: 0.4849 - acc: 0.7886 - precision_78: 0.8004 - recall_78: 0.7689\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78857, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1865s 2s/step - loss: 0.5084 - acc: 0.7662 - precision_78: 0.7719 - recall_78: 0.7559 - val_loss: 0.4849 - val_acc: 0.7886 - val_precision_78: 0.8004 - val_recall_78: 0.7689\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 74s 580ms/step - loss: 0.3740 - acc: 0.8475 - precision_78: 0.8786 - recall_78: 0.8063\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.78857 to 0.84746, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1033s 907ms/step - loss: 0.3585 - acc: 0.8407 - precision_78: 0.8554 - recall_78: 0.8199 - val_loss: 0.3740 - val_acc: 0.8475 - val_precision_78: 0.8786 - val_recall_78: 0.8063\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 73s 576ms/step - loss: 0.5182 - acc: 0.7918 - precision_78: 0.9526 - recall_78: 0.6141\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.84746\n",
      "1139/1139 [==============================] - 1035s 908ms/step - loss: 0.3128 - acc: 0.8612 - precision_78: 0.8716 - recall_78: 0.8473 - val_loss: 0.5182 - val_acc: 0.7918 - val_precision_78: 0.9526 - val_recall_78: 0.6141\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 576ms/step - loss: 0.2771 - acc: 0.8760 - precision_78: 0.8697 - recall_78: 0.8847\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84746 to 0.87605, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1037s 910ms/step - loss: 0.2932 - acc: 0.8763 - precision_78: 0.8850 - recall_78: 0.8650 - val_loss: 0.2771 - val_acc: 0.8760 - val_precision_78: 0.8697 - val_recall_78: 0.8847\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 69s 541ms/step - loss: 0.3079 - acc: 0.8701 - precision_78: 0.9104 - recall_78: 0.8211\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87605\n",
      "1139/1139 [==============================] - 1029s 904ms/step - loss: 0.2699 - acc: 0.8851 - precision_78: 0.8928 - recall_78: 0.8754 - val_loss: 0.3079 - val_acc: 0.8701 - val_precision_78: 0.9104 - val_recall_78: 0.8211\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 72s 567ms/step - loss: 0.3034 - acc: 0.8738 - precision_78: 0.8892 - recall_78: 0.8541\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87605\n",
      "1139/1139 [==============================] - 1032s 906ms/step - loss: 0.2548 - acc: 0.8920 - precision_78: 0.8985 - recall_78: 0.8839 - val_loss: 0.3034 - val_acc: 0.8738 - val_precision_78: 0.8892 - val_recall_78: 0.8541\n",
      "127/127 [==============================] - 186s 1s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 25s 200ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 24s 189ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 25s 197ms/step\n",
      "Acc: 0.906\tP: 0.909\tR: 0.903\n",
      "Acc: 0.901\tP: 0.894\tR: 0.910\n",
      "Acc: 0.903\tP: 0.898\tR: 0.908\n",
      "Acc: 0.901\tP: 0.896\tR: 0.908\n",
      "Acc: 0.911\tP: 0.912\tR: 0.910\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_14 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 107712)       0           global_max_pooling2d_14[0][0]    \n",
      "                                                                 global_average_pooling2d_14[0][0]\n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 107712)       0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "127/127 [==============================] - 210s 2s/step - loss: 0.5532 - acc: 0.7541 - precision_84: 0.8273 - recall_84: 0.6422\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75407, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1948s 2s/step - loss: 0.5046 - acc: 0.7719 - precision_84: 0.7767 - recall_84: 0.7632 - val_loss: 0.5532 - val_acc: 0.7541 - val_precision_84: 0.8273 - val_recall_84: 0.6422\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 75s 588ms/step - loss: 0.3758 - acc: 0.8521 - precision_84: 0.8712 - recall_84: 0.8265\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75407 to 0.85214, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1047s 919ms/step - loss: 0.3605 - acc: 0.8398 - precision_84: 0.8491 - recall_84: 0.8265 - val_loss: 0.3758 - val_acc: 0.8521 - val_precision_84: 0.8712 - val_recall_84: 0.8265\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 71s 558ms/step - loss: 0.3364 - acc: 0.8627 - precision_84: 0.8615 - recall_84: 0.8645\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85214 to 0.86274, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1042s 915ms/step - loss: 0.3162 - acc: 0.8618 - precision_84: 0.8715 - recall_84: 0.8488 - val_loss: 0.3364 - val_acc: 0.8627 - val_precision_84: 0.8615 - val_recall_84: 0.8645\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 572ms/step - loss: 0.3105 - acc: 0.8760 - precision_84: 0.9016 - recall_84: 0.8443\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86274 to 0.87605, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1045s 917ms/step - loss: 0.2928 - acc: 0.8727 - precision_84: 0.8818 - recall_84: 0.8607 - val_loss: 0.3105 - val_acc: 0.8760 - val_precision_84: 0.9016 - val_recall_84: 0.8443\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 74s 583ms/step - loss: 0.3349 - acc: 0.8736 - precision_84: 0.8357 - recall_84: 0.9300\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87605\n",
      "1139/1139 [==============================] - 1046s 918ms/step - loss: 0.2691 - acc: 0.8856 - precision_84: 0.8923 - recall_84: 0.8770 - val_loss: 0.3349 - val_acc: 0.8736 - val_precision_84: 0.8357 - val_recall_84: 0.9300\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 73s 573ms/step - loss: 0.2497 - acc: 0.8945 - precision_84: 0.9116 - recall_84: 0.8738\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87605 to 0.89453, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1046s 919ms/step - loss: 0.2548 - acc: 0.8915 - precision_84: 0.8981 - recall_84: 0.8831 - val_loss: 0.2497 - val_acc: 0.8945 - val_precision_84: 0.9116 - val_recall_84: 0.8738\n",
      "127/127 [==============================] - 197s 2s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 25s 200ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 24s 192ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 25s 198ms/step\n",
      "Acc: 0.900\tP: 0.913\tR: 0.884\n",
      "Acc: 0.897\tP: 0.913\tR: 0.877\n",
      "Acc: 0.904\tP: 0.913\tR: 0.893\n",
      "Acc: 0.899\tP: 0.910\tR: 0.886\n",
      "Acc: 0.908\tP: 0.925\tR: 0.889\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_15 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_15 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 107712)       0           global_max_pooling2d_15[0][0]    \n",
      "                                                                 global_average_pooling2d_15[0][0]\n",
      "                                                                 flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 107712)       0           concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 230s 2s/step - loss: 0.4966 - acc: 0.7935 - precision_90: 0.7550 - recall_90: 0.8689\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79349, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 2008s 2s/step - loss: 0.5021 - acc: 0.7698 - precision_90: 0.7748 - recall_90: 0.7606 - val_loss: 0.4966 - val_acc: 0.7935 - val_precision_90: 0.7550 - val_recall_90: 0.8689\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 74s 583ms/step - loss: 0.4264 - acc: 0.8297 - precision_90: 0.7866 - recall_90: 0.9049\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79349 to 0.82972, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1044s 916ms/step - loss: 0.3582 - acc: 0.8386 - precision_90: 0.8486 - recall_90: 0.8243 - val_loss: 0.4264 - val_acc: 0.8297 - val_precision_90: 0.7866 - val_recall_90: 0.9049\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 72s 570ms/step - loss: 0.5867 - acc: 0.8083 - precision_90: 0.7363 - recall_90: 0.9606\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.82972\n",
      "1139/1139 [==============================] - 1038s 911ms/step - loss: 0.3167 - acc: 0.8602 - precision_90: 0.8673 - recall_90: 0.8506 - val_loss: 0.5867 - val_acc: 0.8083 - val_precision_90: 0.7363 - val_recall_90: 0.9606\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 571ms/step - loss: 0.3039 - acc: 0.8687 - precision_90: 0.8492 - recall_90: 0.8965\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.82972 to 0.86865, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1042s 914ms/step - loss: 0.2896 - acc: 0.8738 - precision_90: 0.8807 - recall_90: 0.8648 - val_loss: 0.3039 - val_acc: 0.8687 - val_precision_90: 0.8492 - val_recall_90: 0.8965\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 76s 597ms/step - loss: 0.2707 - acc: 0.8852 - precision_90: 0.8560 - recall_90: 0.9261\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86865 to 0.88517, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1049s 921ms/step - loss: 0.2688 - acc: 0.8845 - precision_90: 0.8901 - recall_90: 0.8772 - val_loss: 0.2707 - val_acc: 0.8852 - val_precision_90: 0.8560 - val_recall_90: 0.9261\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 75s 589ms/step - loss: 0.2750 - acc: 0.8827 - precision_90: 0.8928 - recall_90: 0.8699\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88517\n",
      "1139/1139 [==============================] - 1044s 917ms/step - loss: 0.2526 - acc: 0.8921 - precision_90: 0.8993 - recall_90: 0.8831 - val_loss: 0.2750 - val_acc: 0.8827 - val_precision_90: 0.8928 - val_recall_90: 0.8699\n",
      "127/127 [==============================] - 223s 2s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 25s 197ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 24s 193ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 26s 205ms/step\n",
      "Acc: 0.899\tP: 0.866\tR: 0.945\n",
      "Acc: 0.899\tP: 0.875\tR: 0.931\n",
      "Acc: 0.899\tP: 0.865\tR: 0.945\n",
      "Acc: 0.904\tP: 0.878\tR: 0.937\n",
      "Acc: 0.907\tP: 0.881\tR: 0.941\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_16 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_16 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 107712)       0           global_max_pooling2d_16[0][0]    \n",
      "                                                                 global_average_pooling2d_16[0][0]\n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 107712)       0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 249s 2s/step - loss: 0.8598 - acc: 0.6893 - precision_96: 0.9694 - recall_96: 0.3908\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68926, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 2210s 2s/step - loss: 0.5019 - acc: 0.7716 - precision_96: 0.7775 - recall_96: 0.7608 - val_loss: 0.8598 - val_acc: 0.6893 - val_precision_96: 0.9694 - val_recall_96: 0.3908\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 73s 575ms/step - loss: 0.4395 - acc: 0.8169 - precision_96: 0.9127 - recall_96: 0.7008\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68926 to 0.81690, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1052s 924ms/step - loss: 0.3601 - acc: 0.8380 - precision_96: 0.8486 - recall_96: 0.8229 - val_loss: 0.4395 - val_acc: 0.8169 - val_precision_96: 0.9127 - val_recall_96: 0.7008\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 76s 597ms/step - loss: 0.5243 - acc: 0.8048 - precision_96: 0.8988 - recall_96: 0.6870\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.81690\n",
      "1139/1139 [==============================] - 1057s 928ms/step - loss: 0.3139 - acc: 0.8628 - precision_96: 0.8718 - recall_96: 0.8507 - val_loss: 0.5243 - val_acc: 0.8048 - val_precision_96: 0.8988 - val_recall_96: 0.6870\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 576ms/step - loss: 0.3654 - acc: 0.8566 - precision_96: 0.8123 - recall_96: 0.9276\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.81690 to 0.85658, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1055s 926ms/step - loss: 0.2921 - acc: 0.8739 - precision_96: 0.8810 - recall_96: 0.8648 - val_loss: 0.3654 - val_acc: 0.8566 - val_precision_96: 0.8123 - val_recall_96: 0.9276\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 74s 581ms/step - loss: 0.2799 - acc: 0.8805 - precision_96: 0.8545 - recall_96: 0.9172\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85658 to 0.88048, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1052s 923ms/step - loss: 0.2709 - acc: 0.8847 - precision_96: 0.8919 - recall_96: 0.8755 - val_loss: 0.2799 - val_acc: 0.8805 - val_precision_96: 0.8545 - val_recall_96: 0.9172\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 76s 595ms/step - loss: 0.2740 - acc: 0.8807 - precision_96: 0.8484 - recall_96: 0.9271\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.88048 to 0.88073, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1053s 925ms/step - loss: 0.2497 - acc: 0.8939 - precision_96: 0.9011 - recall_96: 0.8848 - val_loss: 0.2740 - val_acc: 0.8807 - val_precision_96: 0.8484 - val_recall_96: 0.9271\n",
      "127/127 [==============================] - 239s 2s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 26s 204ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 25s 194ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 26s 203ms/step\n",
      "Acc: 0.915\tP: 0.887\tR: 0.952\n",
      "Acc: 0.917\tP: 0.893\tR: 0.948\n",
      "Acc: 0.916\tP: 0.890\tR: 0.949\n",
      "Acc: 0.918\tP: 0.899\tR: 0.942\n",
      "Acc: 0.925\tP: 0.903\tR: 0.952\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_17 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_17 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 107712)       0           global_max_pooling2d_17[0][0]    \n",
      "                                                                 global_average_pooling2d_17[0][0]\n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 107712)       0           concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 262s 2s/step - loss: 0.5826 - acc: 0.7575 - precision_102: 0.8131 - recall_102: 0.6688\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75752, saving model to /home/matejg/nasnet-wsi.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 2175s 2s/step - loss: 0.5083 - acc: 0.7668 - precision_102: 0.7724 - recall_102: 0.7565 - val_loss: 0.5826 - val_acc: 0.7575 - val_precision_102: 0.8131 - val_recall_102: 0.6688\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 75s 591ms/step - loss: 0.4419 - acc: 0.8300 - precision_102: 0.8945 - recall_102: 0.7482\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.75752 to 0.82997, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1042s 915ms/step - loss: 0.3636 - acc: 0.8357 - precision_102: 0.8483 - recall_102: 0.8175 - val_loss: 0.4419 - val_acc: 0.8300 - val_precision_102: 0.8945 - val_recall_102: 0.7482\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 74s 581ms/step - loss: 0.3191 - acc: 0.8672 - precision_102: 0.8695 - recall_102: 0.8640\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.82997 to 0.86718, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1037s 910ms/step - loss: 0.3224 - acc: 0.8568 - precision_102: 0.8677 - recall_102: 0.8421 - val_loss: 0.3191 - val_acc: 0.8672 - val_precision_102: 0.8695 - val_recall_102: 0.8640\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 72s 568ms/step - loss: 0.2778 - acc: 0.8805 - precision_102: 0.8971 - recall_102: 0.8595\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86718 to 0.88048, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1042s 915ms/step - loss: 0.2931 - acc: 0.8712 - precision_102: 0.8779 - recall_102: 0.8624 - val_loss: 0.2778 - val_acc: 0.8805 - val_precision_102: 0.8971 - val_recall_102: 0.8595\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 71s 556ms/step - loss: 0.2699 - acc: 0.8758 - precision_102: 0.8703 - recall_102: 0.8832\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88048\n",
      "1139/1139 [==============================] - 1035s 908ms/step - loss: 0.2735 - acc: 0.8830 - precision_102: 0.8895 - recall_102: 0.8746 - val_loss: 0.2699 - val_acc: 0.8758 - val_precision_102: 0.8703 - val_recall_102: 0.8832\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 72s 569ms/step - loss: 0.3197 - acc: 0.8588 - precision_102: 0.9434 - recall_102: 0.7634\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88048\n",
      "1139/1139 [==============================] - 1037s 910ms/step - loss: 0.2590 - acc: 0.8905 - precision_102: 0.8966 - recall_102: 0.8828 - val_loss: 0.3197 - val_acc: 0.8588 - val_precision_102: 0.9434 - val_recall_102: 0.7634\n",
      "127/127 [==============================] - 263s 2s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 26s 202ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 25s 195ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 26s 203ms/step\n",
      "Acc: 0.911\tP: 0.922\tR: 0.897\n",
      "Acc: 0.906\tP: 0.925\tR: 0.883\n",
      "Acc: 0.907\tP: 0.919\tR: 0.892\n",
      "Acc: 0.905\tP: 0.926\tR: 0.879\n",
      "Acc: 0.910\tP: 0.933\tR: 0.883\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_18 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_18 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 107712)       0           global_max_pooling2d_18[0][0]    \n",
      "                                                                 global_average_pooling2d_18[0][0]\n",
      "                                                                 flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 107712)       0           concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 286s 2s/step - loss: 0.7122 - acc: 0.7087 - precision_108: 0.8947 - recall_108: 0.4731\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70872, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 2265s 2s/step - loss: 0.5031 - acc: 0.7712 - precision_108: 0.7760 - recall_108: 0.7623 - val_loss: 0.7122 - val_acc: 0.7087 - val_precision_108: 0.8947 - val_recall_108: 0.4731\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 73s 577ms/step - loss: 0.5655 - acc: 0.7767 - precision_108: 0.9432 - recall_108: 0.5890\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70872 to 0.77674, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1054s 925ms/step - loss: 0.3625 - acc: 0.8373 - precision_108: 0.8488 - recall_108: 0.8208 - val_loss: 0.5655 - val_acc: 0.7767 - val_precision_108: 0.9432 - val_recall_108: 0.5890\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 74s 582ms/step - loss: 0.3841 - acc: 0.8526 - precision_108: 0.8173 - recall_108: 0.9083\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77674 to 0.85264, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1052s 924ms/step - loss: 0.3176 - acc: 0.8602 - precision_108: 0.8690 - recall_108: 0.8483 - val_loss: 0.3841 - val_acc: 0.8526 - val_precision_108: 0.8173 - val_recall_108: 0.9083\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 75s 591ms/step - loss: 0.2933 - acc: 0.8770 - precision_108: 0.8468 - recall_108: 0.9207\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85264 to 0.87703, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1055s 926ms/step - loss: 0.2907 - acc: 0.8735 - precision_108: 0.8825 - recall_108: 0.8618 - val_loss: 0.2933 - val_acc: 0.8770 - val_precision_108: 0.8468 - val_recall_108: 0.9207\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 73s 574ms/step - loss: 0.2974 - acc: 0.8684 - precision_108: 0.8330 - recall_108: 0.9216\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87703\n",
      "1139/1139 [==============================] - 1054s 926ms/step - loss: 0.2732 - acc: 0.8832 - precision_108: 0.8915 - recall_108: 0.8727 - val_loss: 0.2974 - val_acc: 0.8684 - val_precision_108: 0.8330 - val_recall_108: 0.9216\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 75s 588ms/step - loss: 0.3013 - acc: 0.8889 - precision_108: 0.8732 - recall_108: 0.9098\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87703 to 0.88886, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1053s 924ms/step - loss: 0.2528 - acc: 0.8926 - precision_108: 0.8988 - recall_108: 0.8848 - val_loss: 0.3013 - val_acc: 0.8889 - val_precision_108: 0.8732 - val_recall_108: 0.9098\n",
      "127/127 [==============================] - 287s 2s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 26s 201ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 25s 197ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 26s 206ms/step\n",
      "Acc: 0.904\tP: 0.885\tR: 0.929\n",
      "Acc: 0.908\tP: 0.895\tR: 0.924\n",
      "Acc: 0.906\tP: 0.890\tR: 0.926\n",
      "Acc: 0.904\tP: 0.891\tR: 0.920\n",
      "Acc: 0.913\tP: 0.904\tR: 0.923\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_19 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_19 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 107712)       0           global_max_pooling2d_19[0][0]    \n",
      "                                                                 global_average_pooling2d_19[0][0]\n",
      "                                                                 flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 107712)       0           concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 321s 3s/step - loss: 0.8546 - acc: 0.6915 - precision_114: 0.9360 - recall_114: 0.4110\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69147, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 2423s 2s/step - loss: 0.4966 - acc: 0.7688 - precision_114: 0.7736 - recall_114: 0.7600 - val_loss: 0.8546 - val_acc: 0.6915 - val_precision_114: 0.9360 - val_recall_114: 0.4110\n",
      "Epoch 2/6\n",
      "127/127 [==============================] - 73s 576ms/step - loss: 0.4700 - acc: 0.8051 - precision_114: 0.7474 - recall_114: 0.9216\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69147 to 0.80508, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1064s 934ms/step - loss: 0.3613 - acc: 0.8364 - precision_114: 0.8494 - recall_114: 0.8177 - val_loss: 0.4700 - val_acc: 0.8051 - val_precision_114: 0.7474 - val_recall_114: 0.9216\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 74s 583ms/step - loss: 0.3757 - acc: 0.8640 - precision_114: 0.8337 - recall_114: 0.9093\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.80508 to 0.86397, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1063s 934ms/step - loss: 0.3168 - acc: 0.8622 - precision_114: 0.8719 - recall_114: 0.8492 - val_loss: 0.3757 - val_acc: 0.8640 - val_precision_114: 0.8337 - val_recall_114: 0.9093\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 73s 577ms/step - loss: 0.3019 - acc: 0.8728 - precision_114: 0.9233 - recall_114: 0.8132\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86397 to 0.87284, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1063s 933ms/step - loss: 0.2927 - acc: 0.8747 - precision_114: 0.8833 - recall_114: 0.8634 - val_loss: 0.3019 - val_acc: 0.8728 - val_precision_114: 0.9233 - val_recall_114: 0.8132\n",
      "Epoch 5/6\n",
      "127/127 [==============================] - 76s 600ms/step - loss: 0.2968 - acc: 0.8780 - precision_114: 0.9219 - recall_114: 0.8260\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87284 to 0.87802, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1069s 938ms/step - loss: 0.2716 - acc: 0.8818 - precision_114: 0.8896 - recall_114: 0.8718 - val_loss: 0.2968 - val_acc: 0.8780 - val_precision_114: 0.9219 - val_recall_114: 0.8260\n",
      "Epoch 6/6\n",
      "127/127 [==============================] - 76s 595ms/step - loss: 0.2826 - acc: 0.8842 - precision_114: 0.9041 - recall_114: 0.8595\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.87802 to 0.88418, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1066s 936ms/step - loss: 0.2584 - acc: 0.8903 - precision_114: 0.8959 - recall_114: 0.8833 - val_loss: 0.2826 - val_acc: 0.8842 - val_precision_114: 0.9041 - val_recall_114: 0.8595\n",
      "127/127 [==============================] - 307s 2s/step\n",
      "Horizontal augment.\n",
      "127/127 [==============================] - 26s 205ms/step\n",
      "Vertical augment\n",
      "127/127 [==============================] - 25s 200ms/step\n",
      "Horizontal+Vertical augment\n",
      "127/127 [==============================] - 26s 206ms/step\n",
      "Acc: 0.911\tP: 0.935\tR: 0.883\n",
      "Acc: 0.896\tP: 0.932\tR: 0.855\n",
      "Acc: 0.905\tP: 0.932\tR: 0.874\n",
      "Acc: 0.903\tP: 0.938\tR: 0.863\n",
      "Acc: 0.905\tP: 0.938\tR: 0.866\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 10, 10, 1056) 4269716     input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_20 (Global (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_20 (Gl (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 105600)       0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 107712)       0           global_max_pooling2d_20[0][0]    \n",
      "                                                                 global_average_pooling2d_20[0][0]\n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 107712)       0           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            107713      dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 4,377,429\n",
      "Trainable params: 4,340,691\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n",
      "127/127 [==============================] - 334s 3s/step - loss: 0.4898 - acc: 0.7824 - precision_120: 0.7553 - recall_120: 0.8354\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78241, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 2529s 2s/step - loss: 0.5122 - acc: 0.7676 - precision_120: 0.7726 - recall_120: 0.7586 - val_loss: 0.4898 - val_acc: 0.7824 - val_precision_120: 0.7553 - val_recall_120: 0.8354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6\n",
      "127/127 [==============================] - 73s 572ms/step - loss: 0.4135 - acc: 0.8369 - precision_120: 0.8507 - recall_120: 0.8172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.78241 to 0.83687, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1069s 939ms/step - loss: 0.3571 - acc: 0.8406 - precision_120: 0.8508 - recall_120: 0.8261 - val_loss: 0.4135 - val_acc: 0.8369 - val_precision_120: 0.8507 - val_recall_120: 0.8172\n",
      "Epoch 3/6\n",
      "127/127 [==============================] - 73s 572ms/step - loss: 0.4085 - acc: 0.8374 - precision_120: 0.7834 - recall_120: 0.9325\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83687 to 0.83736, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1067s 937ms/step - loss: 0.3189 - acc: 0.8613 - precision_120: 0.8690 - recall_120: 0.8508 - val_loss: 0.4085 - val_acc: 0.8374 - val_precision_120: 0.7834 - val_recall_120: 0.9325\n",
      "Epoch 4/6\n",
      "127/127 [==============================] - 74s 580ms/step - loss: 0.2940 - acc: 0.8716 - precision_120: 0.8646 - recall_120: 0.8812\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.83736 to 0.87161, saving model to /home/matejg/nasnet-wsi.h5\n",
      "1139/1139 [==============================] - 1069s 938ms/step - loss: 0.2903 - acc: 0.8750 - precision_120: 0.8828 - recall_120: 0.8650 - val_loss: 0.2940 - val_acc: 0.8716 - val_precision_120: 0.8646 - val_recall_120: 0.8812\n",
      "Epoch 5/6\n",
      "1138/1139 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.8837 - precision_120: 0.8904 - recall_120: 0.8751"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-344a7ace8da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdivide_round_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdivide_round_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_valid_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3164\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3166\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3167\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3168\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got two values for keyword '{}'.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munused_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Keyword arguments {} unknown.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_call_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_proto_serialized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m           executor_type=function_call_options.executor_type)\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[0;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[1;32m   1081\u001b[0m       outputs = gen_functional_ops.stateful_partitioned_call(\n\u001b[1;32m   1082\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m           executor_type=executor_type)\n\u001b[0m\u001b[1;32m   1084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m       outputs = gen_functional_ops.partitioned_call(\n",
      "\u001b[0;32m~/Test/test/lib/python3.5/site-packages/tensorflow/python/ops/gen_functional_ops.py\u001b[0m in \u001b[0;36mstateful_partitioned_call\u001b[0;34m(args, Tout, f, config, config_proto, executor_type, name)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;34m\"StatefulPartitionedCall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;34m\"Tout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \"executor_type\", executor_type)\n\u001b[0m\u001b[1;32m    484\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10,100):\n",
    "    model = get_model_classif_nasnet()\n",
    "    new_train_fn = train_fn[train_fn['class'] == '0'].sample(n=len(train_fn[train_fn['class'] == '1']))\n",
    "    new_train_fn = pd.concat([new_train_fn, train_fn[train_fn['class'] == '1']])\n",
    "    new_train_fn = new_train_fn.sample(frac=1)\n",
    "\n",
    "    new_valid_fn = valid_fn[valid_fn['class'] == '0'].sample(n=len(valid_fn[valid_fn['class'] == '1']))\n",
    "    new_valid_fn = pd.concat([new_valid_fn, valid_fn[valid_fn['class'] == '1']])\n",
    "    new_valid_fn = new_valid_fn.sample(frac=1)\n",
    "\n",
    "    new_test_fn = test_fn[test_fn['class'] == '0'].sample(n=len(test_fn[test_fn['class'] == '1']))\n",
    "    new_test_fn = pd.concat([new_test_fn, valid_fn[test_fn['class'] == '1']])\n",
    "    new_test_fn = new_test_fn.sample(frac=1)\n",
    "\n",
    "    batch_size = 32\n",
    "    checkpoint = ModelCheckpoint('/home/matejg/nasnet-wsi.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
    "\n",
    "    _ = model.fit_generator(\n",
    "        test_data_gen(new_train_fn, batch_size),\n",
    "        validation_data=test_data_gen(new_valid_fn, batch_size, shuffle=False),\n",
    "        epochs=6, verbose=1,\n",
    "        callbacks=[checkpoint],\n",
    "        steps_per_epoch=divide_round_up(len(new_train_fn), batch_size),\n",
    "        validation_steps=divide_round_up(len(new_valid_fn), batch_size)\n",
    "    )\n",
    "\n",
    "    used_ds = new_test_fn\n",
    "    model.load_weights('/home/matejg/nasnet-wsi.h5')\n",
    "\n",
    "    res_normal = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='n', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "\n",
    "    res_horizontal = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='h', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "\n",
    "    res_vertical = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='v', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "\n",
    "    res_both = model.predict_generator(\n",
    "        test_data_gen(used_ds, batch_size, augment='b', shuffle=False),\n",
    "        verbose=1, steps=divide_round_up(len(used_ds), batch_size)\n",
    "    )\n",
    "\n",
    "    res_combined = np.array((res_normal.ravel() * res_horizontal.ravel() * res_vertical.ravel() * res_both.ravel()) ** 0.25)\n",
    "    for res in [res_normal, res_vertical, res_horizontal, res_both, res_combined]:\n",
    "        acc = tf.keras.metrics.BinaryAccuracy()\n",
    "        acc.update_state(used_ds['class'].ravel().astype(np.float), res.ravel())\n",
    "\n",
    "        p = tf.keras.metrics.Precision()\n",
    "        p.update_state(used_ds['class'].ravel().astype(np.float), res.ravel())\n",
    "\n",
    "        r = tf.keras.metrics.Recall()\n",
    "        r.update_state(used_ds['class'].ravel().astype(np.float), res.ravel())\n",
    "\n",
    "        print('Acc: {:.3f}\\tP: {:.3f}\\tR: {:.3f}'.format(acc.result().numpy(), p.result().numpy(), r.result().numpy()))\n",
    "        all_runs[i] = (acc.result().numpy(), p.result().numpy(), r.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290453"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_fn['class'] == '0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
