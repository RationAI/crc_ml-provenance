{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import data, io, filters\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.color import rgb2hed\n",
    "import skimage\n",
    "import skimage.morphology\n",
    "import skimage.exposure\n",
    "import skimage.util\n",
    "import imageio\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "from skimage.morphology import diamond, binary_dilation, closing, square\n",
    "\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/PIL/Image.py:2735: DecompressionBombWarning: Image size (91115640 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    }
   ],
   "source": [
    "#The crop is not the part of the algorithm\n",
    "im_ce = io.imread(\"CK-DAB-H-HR2-16PgR-B.png\")[6000:12000, ...]\n",
    "im_he = io.imread(\"HE-HR2-16PgR-B.png\")[6000:12000, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2h(im):\n",
    "    im_rgb = im[:,:,:3]\n",
    "    im_hed = rgb2hed(im_rgb)\n",
    "    im_h = im_hed[:, :, 0]\n",
    "    return skimage.exposure.rescale_intensity(im_h, out_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_ce_gray = rgb2gray(im_ce)\n",
    "im_he_gray = rgb2gray(im_he)\n",
    "\n",
    "im_ce_h = rgb2h(im_ce)\n",
    "im_he_h = rgb2h(im_he)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns a part of an image given coordinates\n",
    "\n",
    "def get_subimage(coords, im, relative_coords=(0,0)):\n",
    "    return im[coords[0]+relative_coords[0]:coords[2]+relative_coords[1], \n",
    "              coords[1]+relative_coords[0]:coords[3]+relative_coords[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmentation is based on finding objects of a minimal size. Objects are represented by the class Segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Segment:\n",
    "    def __init__(self, region):\n",
    "        self.region = region   \n",
    "\n",
    "    def get_subimage(self, im):\n",
    "        return im[self.region.bbox[0]:self.region.bbox[2], \n",
    "                  self.region.bbox[1]:self.region.bbox[3]]\n",
    "    \n",
    "    def get_min_coords(self):\n",
    "        return self.region.bbox[0], self.region.bbox[1]\n",
    "    \n",
    "    def get_max_coords(self):\n",
    "        return self.region.bbox[2], self.region.bbox[3]\n",
    "    \n",
    "    def get_area(self):\n",
    "        return self.region.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns a list of objects larger than min_area\n",
    "\n",
    "def segment_binary_objects(im, min_area):\n",
    "    bw = closing(im, square(3))\n",
    "    cleared = clear_border(bw)\n",
    "    label_image = label(cleared)\n",
    "\n",
    "    return [Segment(region) for region in regionprops(label_image) if (region.area >= min_area)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Applies the thresholding (Otsu) twice to remove too small and too large values\n",
    "\n",
    "def double_otsu_threshold(im):\n",
    "    thr1 = threshold_otsu(im)\n",
    "    im_thr1 = im * (im < thr1)\n",
    "    thr2 = threshold_otsu(im_thr1)\n",
    "    return (im_thr1 > thr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,2)+np.ones((2,3)).shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adds an empty margin to an image.\n",
    "\n",
    "def add_margin(im, mw):\n",
    "    x = np.zeros((im.shape[0]+(2*mw), im.shape[1]+(2*mw))+im.shape[2:])\n",
    "    x[mw:im.shape[0]+mw, mw:im.shape[1]+mw] += im\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The number of columns of the samples\n",
    "NUMBER_OF_COLUMNS = 3\n",
    "#Minimum object size in the input image\n",
    "MIN_OBJECT_SIZE_ORIGINAL = 100\n",
    "#Implementation detail: To remove borders around a sample, we identify the very large object in the center\n",
    "MIN_OBJECT_SIZE_SECOND = 2000\n",
    "#The object searching algorithm (regionprops) does not like objects touching the border of the image, so we add a small margin\n",
    "CORRECTION_MARGIN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_segments(im_h, im_gray):\n",
    "    segments_unsorted = segment_binary_objects(add_margin(im_gray > 0, CORRECTION_MARGIN), 100)\n",
    "    \n",
    "    #Sorts the samples (by rows)\n",
    "    segments_sorted = sum([\n",
    "        sorted(\n",
    "            sorted(segments_unsorted, key=lambda x:x.get_min_coords()[0])[i:i+NUMBER_OF_COLUMNS], \n",
    "            key=lambda x: x.get_min_coords()[1]) \n",
    "        for i in range(0, math.floor(len(segments_unsorted)), NUMBER_OF_COLUMNS)],[])\n",
    "    \n",
    "    im_segments = list(map(lambda s: double_otsu_threshold(s.get_subimage(add_margin(im_h, CORRECTION_MARGIN))), segments_sorted))\n",
    "\n",
    "    #This part removes the margins in the already segmented samples\n",
    "    segments2 = list(map(lambda i: segment_binary_objects(add_margin(binary_dilation(i, diamond(10)), CORRECTION_MARGIN), 2000)[0], \n",
    "                       im_segments))\n",
    "\n",
    "    im_segments2 = list(map(lambda si: si[0].get_subimage(add_margin(si[1], CORRECTION_MARGIN)), zip(segments2, im_segments)))\n",
    "\n",
    "    #Get coordinates of the samples in the original image\n",
    "    segment_coordinates = list(map(lambda x: (x[0].get_min_coords()[0] - 2*CORRECTION_MARGIN + x[1].get_min_coords()[0],\n",
    "                                         x[0].get_min_coords()[1] - 2*CORRECTION_MARGIN + x[1].get_min_coords()[1],\n",
    "                                         x[0].get_min_coords()[0] - 2*CORRECTION_MARGIN + x[1].get_max_coords()[0],\n",
    "                                         x[0].get_min_coords()[1] - 2*CORRECTION_MARGIN + x[1].get_max_coords()[1]), \n",
    "                              zip(segments_sorted, segments2))) \n",
    "    \n",
    "    return list(zip(im_segments2, segment_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments_ce = get_segments(im_ce_h, im_ce_gray)\n",
    "segments_he = get_segments(im_he_h, im_he_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registration using SimpleElastix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_he_h_ = get_subimage(segments_he[IMAGE_INDEX][1], im_he_h) * segments_he[IMAGE_INDEX][0]\n",
    "im_ce_h_ = get_subimage(segments_ce[IMAGE_INDEX][1], im_ce_h) * segments_ce[IMAGE_INDEX][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elastixImageFilter = sitk.ElastixImageFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_fixed = sitk.GetImageFromArray(im_he_h_.astype(np.float32))\n",
    "elastixImageFilter.SetFixedImage(im_fixed);\n",
    "\n",
    "im_moving = sitk.GetImageFromArray(im_ce_h_.astype(np.float32))\n",
    "elastixImageFilter.SetMovingImage(im_moving);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SimpleITK.SimpleITK.Image; proxy of <Swig Object of type 'std::vector< itk::simple::Image >::value_type *' at 0x7eff7186ded0> >"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastixImageFilter.SetParameterMap(sitk.GetDefaultParameterMap(\"translation\"))\n",
    "elastixImageFilter.AddParameterMap(sitk.GetDefaultParameterMap('affine'))\n",
    "elastixImageFilter.Execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_result = elastixImageFilter.GetResultImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_fixed_np = sitk.GetArrayFromImage(im_fixed)\n",
    "im_moving_np = sitk.GetArrayFromImage(im_moving)\n",
    "im_result_np = sitk.GetArrayFromImage(im_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "io.imsave(\"test.tif\", im_result_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registration (naive, just translation + squared error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The registration algorithm is extremely naive. Just add a margin to the he image, and move the ce image around minimizing the squared loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(im1, im2, x, y):\n",
    "    xx, yy = im2.shape\n",
    "    cut = im1[x:(x+xx), y:(y+yy)]\n",
    "    loss = np.sum((cut - im2)**2)\n",
    "    print(x, y, loss)\n",
    "    return x, y, loss\n",
    "\n",
    "#This gives the relative coordinates of im2 (supposed to be ce) in im1\n",
    "\n",
    "def get_relative_coords(im1, im2):\n",
    "    print(\"Image shapes: \", im1.shape, im2.shape)\n",
    "    l = [get_loss(im1, im2, x, y) for x in range(0, im1.shape[0]-im2.shape[0]) for y in range(0, im1.shape[1]-im2.shape[1])]\n",
    "    b = sorted(l, key=lambda x: x[2])[0]\n",
    "    return (b[0], b[1])\n",
    "\n",
    "def max_diff(im1, im2):\n",
    "    x, y = im1.shape\n",
    "    u, v = im2.shape\n",
    "    return max(max(u-x, v-y), 0)\n",
    "\n",
    "SEARCH_MARGIN = 10\n",
    "\n",
    "#Sizes of the margins added to he samples to be able to move ce samples around\n",
    "margin_he = list(map(lambda x: max_diff(x[0][0], x[1][0])+SEARCH_MARGIN, zip(segments_he, segments_ce)))\n",
    "\n",
    "#The registration: Gives the relative coordinates of ce in the he with the added margin\n",
    "\n",
    "relative_coords_ce_in_he = list(map(lambda he, ce, marg: np.array(get_relative_coords(add_margin(he[0], marg), ce[0])), \n",
    "                               segments_he, segments_ce, margin_he))\n",
    "\n",
    "# Obtaining registered images\n",
    "\n",
    "#Just choose which sample you want to use\n",
    "IMAGE_INDEX = 10\n",
    "\n",
    "def add_inside_image(im, coords, im_to_add):\n",
    "    z1 = im_to_add.shape[0]\n",
    "    z2 = im_to_add.shape[1]\n",
    "    c1 = coords[0]\n",
    "    c2 = coords[1]\n",
    "\n",
    "    im[c1:c1+z1, c2:c2+z2] += im_to_add\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### superimpose gray CE and gray HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_he = add_margin(get_subimage(segments_he[IMAGE_INDEX][1], im_he_gray), margin_he[IMAGE_INDEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_ce = add_inside_image(np.zeros(result_he.shape), \n",
    "                             relative_coords_ce_in_he[IMAGE_INDEX], \n",
    "                             get_subimage(segments_ce[IMAGE_INDEX][1], im_ce_gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_superimposed = ([0,1,0] * gray2rgb(np.array(result_he, dtype=float)) * 0.5 + \n",
    "          [1,0,0] * gray2rgb(np.array(result_ce, dtype=float)) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "io.imsave(\"test.png\", im_superimposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill holes in CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2dab(im):\n",
    "    im_rgb = im[:,:,:3]\n",
    "    im_hed = rgb2hed(im_rgb)\n",
    "    im_h = im_hed[:, :, 2]\n",
    "    return skimage.exposure.rescale_intensity(im_h, out_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_ce_dab_mask = double_otsu_threshold(rgb2dab(get_subimage(segments_ce[IMAGE_INDEX][1], im_ce)))\n",
    "i_ce_h_mask = double_otsu_threshold(rgb2h(get_subimage(segments_ce[IMAGE_INDEX][1], im_ce)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = skimage.measure.label(1-i_ce_dab_mask.astype(int))\n",
    "regs = skimage.measure.regionprops(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_AREA=100\n",
    "MAX_AREA=200\n",
    "H_PROPORTION=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holes=np.zeros(i_ce_dab_mask.shape)\n",
    "for region in regs:\n",
    "    if region.area<MAX_AREA:\n",
    "        coords = tuple(zip(*region.coords))\n",
    "        if region.area<MIN_AREA:\n",
    "            holes[coords]=1\n",
    "        else:\n",
    "            H_values = (1-i_ce_h_mask)[coords]\n",
    "            meanH = np.mean(H_values)\n",
    "            if meanH >= H_PROPORTION:\n",
    "                holes[coords]=1        \n",
    "\n",
    "filled_holes = holes + i_ce_dab_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(848, 748)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_holes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### superimpose HE and CE with filled holes (elastix registration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filled_holes_elastix_im = sitk.GetImageFromArray(filled_holes.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = sitk.Transformix(filled_holes_elastix_im, elastixImageFilter.GetTransformParameterMap())\n",
    "filled_holes_result_im = sitk.GetArrayFromImage(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "io.imsave(\"test.tif\", im_composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he = get_subimage(segments_he[IMAGE_INDEX][1], im_he)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "he_masked_with_ce_with_filled_holes = np.stack([he[:,:,0],\n",
    "         he[:,:,1]+ filled_holes_result_im,\n",
    "         he[:,:,2]],\n",
    "        axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [-0.2503100633621216, 2.375198420356302]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "io.imsave(\"he_masked_with_ce_with_filled_holes_elastix_registration.png\", he_masked_with_ce_with_filled_holes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### superimpose HE and CE with filled holes (naive registration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he = add_margin(get_subimage(segments_he[IMAGE_INDEX][1], im_he), margin_he[IMAGE_INDEX])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filled_holes_ext = add_inside_image(np.zeros(he.shape[:2]), \n",
    "                             relative_coords_ce_in_he[IMAGE_INDEX], \n",
    "                             filled_holes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "io.imshow(he)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "io.imshow(filled_holes_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_masked_with_ce_with_filled_holes = np.stack([0.8*he[:,:,0],\n",
    "         0.2*he[:,:,1]+ 0.8*filled_holes_ext,\n",
    "         0.8*he[:,:,2]],\n",
    "        axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "io.imshow(he_masked_with_ce_with_filled_holes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "io.imsave(\"he_masked_with_ce_with_filled_holes_naive_registration.png\", he_masked_with_ce_with_filled_holes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
